---
title: "Flowchart"
author: "Milou Sep"
date: "2/4/2021"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls()) #clean environment
# load files from OSF
library(osfr)
# Authenticate to OSF (see: http://centerforopenscience.github.io/osfr/articles/auth.html). Via osf_auth("PAT") in the commentline. (note PAT can be derived from OSF)
```


```{r}
library(readxl)
library(dplyr)
```

# Search

 Compare PMIDs in search 1 and 2 of trace & remove duplicates
 code to remove duplicates from search 2 in TRACE project
 written by Milou Sep
 
## retrieve OSF files 
```{r }
osf_retrieve_file("7k6wh") %>% osf_download(path = "data", conflicts="overwrite") # trace dataset search 1
osf_retrieve_file("7kdmu") %>% osf_download(path = "data", conflicts="overwrite") # human search 2
osf_retrieve_file("fs2gq") %>% osf_download(path = "data", conflicts="overwrite") # animal search 2

osf_retrieve_file("nqgaf") %>% osf_download(path = "data", conflicts="overwrite") # human search 3
osf_retrieve_file("s3ake") %>% osf_download(path = "data", conflicts="overwrite") # animal search 3
```

## load data search 1
```{r warning=FALSE}
# load data search1 animal hits
search1_animal <- read_excel("data/Review PTSD Cognition AbstractScreening_Overeenstemming EG & MS v15.11.2016.xlsx", sheet = "Animal hits n=178 SSv18.10.2016", col_types = "numeric")
search1_animal_uPMID <- unique(search1_animal$PMID)
rm(search1_animal)

search1_animal <- search1_animal_uPMID[1:(length(search1_animal_uPMID)-2)]# remove last 2 items in vector (these are not PMIDs, but countings/notes)
n.s1.A = length(search1_animal) #178
n.s1.A
```


```{r warning=FALSE}
# load data search1 human hits
search1_human <- read_excel("data/Review PTSD Cognition AbstractScreening_Overeenstemming EG & MS v15.11.2016.xlsx",  sheet = "Human Hits n=292 SSv12.10.2016", col_types = "numeric")
search1_human_uPMID <- unique(search1_human$`PMID (op alfabet)`)
rm(search1_human)

search1_human <- search1_human_uPMID[1:(length(search1_human_uPMID)-2)]# remove last 2 items in vector (these are not PMIDs, but countings/notes)
n.s1.H = length(search1_human) #292
n.s1.H
```
```{r}
file.remove("data/Review PTSD Cognition AbstractScreening_Overeenstemming EG & MS v15.11.2016.xlsx")
```


## load data search 2
```{r}
animal_search2 <- read.table("data/pubmed_result_search2_animal 6.1.20.txt",  quote="\"", comment.char="")
human_search2<- read.table("data/pubmed_result_search2_human 6.1.20.txt", quote="\"", comment.char="")
```

## compare search 1 and 2

### Compare animal hits & and save unique id's to csv
```{r }
animal_search2[!animal_search2$V1 %in% search1_animal_uPMID,] -> animal_search2_uniq
n.s2.A = length(animal_search2_uniq)
# write.table(animal_search2_uniq, file = "animal_search2_unique.csv", sep = ';', row.names = F)
n.s2.A
```

### Compare human hits & and save unique id's to csv
```{r}
# human_search2$V1 %in% search1_human_uPMID #vgl search 2 met search1 "welke hits van search 2 zitten in search 1?"
human_search2[!human_search2$V1 %in% search1_human_uPMID,] -> human_search2_uniq # "select the hits of search 2 that are NOT in search 1"
n.s2.H = length(human_search2_uniq)
# write.table(human_search2_uniq, file = "human_search2_unique.csv", sep = ';', row.names = F)
n.s2.H
```

## load search 3
```{r }
animal_search3 <- read.table("data/pmid.animal.s3.learn.22.5.20.txt",  quote="\"", comment.char="")
nrow(animal_search3)
```


```{r }
human_search3<- read.table("data/pmid.human.s3.learn.22.5.20.txt", quote="\"", comment.char="")
nrow(human_search3)
```

## compare search 1,2,3

### Compare human hits 
```{r }
# After search 2, SC updated (task & behavioral part), script to extract unique id's from new search (=not checked in search 1 or 2)
# 18.5.20 Milou Sep

# # to check new search comments:  (manually checked and now all fine)
# # which search 1 not in search 3
# search1_animal[!search1_animal %in% animal_search3$V1]
# search1_human[!search1_human %in% human_search3$V1]

# Compare human hits 
all(search1_human %in% human_search2$V1) # All items in search 1 are also in search 2
human_search3[!human_search3$V1 %in% human_search2$V1,]  -> unique.search3.human # therefore search 3 compared to search 2
n.s3.H = length(unique.search3.human) # (met cognitie) 412 -> met alleen learning / memory: 286
# write.table(unique.search3.human, file = "human_search3_unique.csv", sep = ';', row.names = F)
n.s3.H
```

### Compare animal hits 
```{r }
all(search1_animal %in% animal_search2$V1) # All items in search 1 are also in search 2
animal_search3[!animal_search3$V1 %in% animal_search2$V1,]  -> unique.search3.animal # therefore search 3 compared to search 2
n.s3.A = length(unique.search3.animal) # (met cognitie) 318 -> met alleen learning/memory: 291
 # write.table(unique.search3.animal, file = "animal_search3_unique.csv", sep = ';', row.names = F)
n.s3.A
```

## remove local copies of downloaded OSF files
```{r }
file.remove(c(#"data/TRACE Dataset v28.2.19.xlsx",
              "data/pubmed_result_search2_animal 6.1.20.txt","data/pubmed_result_search2_human 6.1.20.txt",
              "data/pmid.animal.s3.learn.22.5.20.txt", "data/pmid.human.s3.learn.22.5.20.txt"))
```



## Conclusions:
- Total unique animal papers screened: 178 (S1) + 114 (S2) + 252 (S3) =
```{r}
# 178+114+252-> total.screened.preclinical 544

total.screened.preclinical = n.s1.A +
# n.s1.H
n.s2.A +
# n.s2.H
# n.s3.H
n.s3.A

total.screened.preclinical
```

- Total unique human papers screened: 292 (S1) + 142 (S2) + 681 (S3)
```{r}
# 292+142+681->total.screened.clinical 1115

total.screened.clinical = #n.s1.A +
n.s1.H +
# n.s2.A +
n.s2.H +
n.s3.H
# n.s3.A

total.screened.clinical
```



# Screening

## S1 screening

(vast uitgezocht voor eerder ppts)-> hier is inderdaad al een flowchart van op het netwerk en hier: https://osf.io/qbvzu/
kijk of die klopt met wat je krijgt als je hem recreeerd
in eerdere versies flowchart wel 91 inclusies.. in laatste v 63?
Deze aantallen kloppen werl met eerdere versie flowchart (dus voor wrls exclussie in analyses..)
wrsl door verandering in meta-analys (/ missing waarden daar..)
in nice 91... in cns 63 (daar tussen zijn de analyses verander / afgemaakt)

### load data
(new datafile on OSF 4.2.20)
```{r}

```

### Post-screeing inclusions inclusions

NOTE, van hier naar volgende stap is dus "excluded in full-text screening"

```{r}
osf_retrieve_file("tqmwb") %>% osf_download(path = "data", conflicts="overwrite") # screening & data extraction S1
data.s1 <- read_excel("data/TRACE data_collection_search1.xlsx", na = c(" ", "-"))#

# str(data.s1)
data.s1 %>%  
  filter(`Screening_AbstractScreening_EG (1=include; 0 = exclude)` == 1 | `Screening_AbstractScreening_MS (1=include; 0 = exclude)` ==1) %>% 
    group_by(subject=`Screening_Human (1) of Animal (2)`) %>%
    distinct(Reference_PMID) %>% tally() ->s1.n.post.screening
s1.n.post.screening
```

```{r}
s1.n.post.screening[1,2] + s1.n.post.screening[2,2]
# 157 + 87
```

### data included for extraction (= included after full text screening)
```{r}
 glimpse(data.s1)
data.s1 %>% 
  filter(inclusion == 1) %>% 
  group_by(subject=`Screening_Human (1) of Animal (2)`) %>%
  select(subject,Reference_PMID) %>% 
  distinct(Reference_PMID) %>% tally() -> s1.n.in.data
s1.n.in.data
```


```{r}
file.remove(c("data/TRACE data_collection_search1.csv"))
```


## S2 screening

code from "compare_abstract_screening_search2.r code
compare abstract screening search 2
written by Milou Sep (8.5.20)
 
### Step 1 check inconsistencies in abstract screening ----------------------
```{r eval=FALSE, include=FALSE}
# load data
osf_retrieve_file("pu6bf") %>% osf_download(path = "data", conflicts="overwrite")  #abstract screening search2 SH
osf_retrieve_file("56fyu") %>% osf_download(path = "data", conflicts="overwrite")  #abstract screening search2 MS

SH_animal.S2 <- read_excel("data/TRACE_screening_search2_SH.xlsx", sheet = "screening search 2 animal")#, col_types = "numeric")
MS_animal.S2 <- read_excel("data/TRACE_screening_search2_MS.xlsx", sheet = "screening search 2 animal")#, col_types = "numeric")

SH_human.S2 <- read_excel("data/TRACE_screening_search2_SH.xlsx", sheet = "screening search 2 human")#, col_types = "numeric")
MS_human.S2 <- read_excel("data/TRACE_screening_search2_MS.xlsx", sheet = "screening search 2 human")#, col_types = "numeric")

# remove rows with all NA's in screening SH
SH_animal.S2[rowSums(is.na(SH_animal.S2)) != ncol(SH_animal.S2), ]->SH_animal.S2
SH_human.S2[rowSums(is.na(SH_human.S2)) != ncol(SH_human.S2), ]->SH_human.S2

# make unique column names
colnames(SH_animal.S2) <- paste(colnames(SH_animal.S2),"SH", sep = "_")
colnames(MS_animal.S2) <- paste(colnames(MS_animal.S2),"MS", sep = "_")
# 
colnames(SH_human.S2) <- paste(colnames(SH_human.S2),"SH", sep = "_")
colnames(MS_human.S2) <- paste(colnames(MS_human.S2),"MS", sep = "_")


# order animal data by PMID 
SH_animal.S2 %>% arrange(Reference_PMID_SH) -> SH_animal.S22
MS_animal.S2 %>% arrange(Reference_PMID_MS) -> MS_animal.S22

# check if ordering is the same:
all.equal(SH_animal.S22$Reference_PMID_SH, MS_animal.S22$Reference_PMID_MS)

# order human data by PMID 
SH_human.S2 %>% arrange(Reference_PMID_SH)->SH_human.S22
MS_human.S2 %>% arrange(Reference_PMID_MS)->MS_human.S22
# check if ordering is the same:
all.equal(SH_human.S22$Reference_PMID_SH,MS_human.S22$Reference_PMID_MS)

# merge data
cbind(SH_animal.S22, MS_animal.S22)->animal
cbind(SH_human.S22, MS_human.S22)->human

# select only PMID & ref.
# human %>% select(Reference_PMID_SH, inclusion_SH, Reference_PMID_MS, inclusion_MS) ->df.h
# animal %>% select(Reference_PMID_SH, Inclusion_SH, Reference_PMID_MS, inclusion_MS) ->df.a

# recode to same scale: 1=inclusion; 0=exclusion; ?=full text check needed
human %>% mutate(
  inclusion_MS=
    case_when(
      inclusion_MS==1 ~"yes",
      inclusion_MS==0 ~"no",
      grepl("?",inclusion_MS, fixed = T) ~ '?')
)->human_recoded

animal %>% mutate(
  inclusion_MS=
    case_when(
      inclusion_MS==1 ~"yes",
      inclusion_MS==0 ~"no",
      grepl("?",inclusion_MS, fixed = T) ~ '?')
) ->animal_recoded


# select equal rows
# df.a2 %>% filter((Reference_PMID_SH==Reference_PMID_MS) & (Inclusion_SH == inclusion_MS)) %>% nrow()
animal_recoded %>% mutate(
  conclusion1= case_when(
    # Inclusion_SH == '?' ~ 'full_text_check',
    # Inclusion_MS == '?' ~ 'full_text_check',
    (Reference_PMID_SH!=Reference_PMID_MS) ~'PMIDincor',
    # (Reference_PMID_SH==Reference_PMID_MS) & Inclusion_SH != '?' & (Inclusion_SH == inclusion_MS) ~ 'equal',
    (Reference_PMID_SH==Reference_PMID_MS) & (Inclusion_SH == inclusion_MS) ~ 'same',
    (Reference_PMID_SH==Reference_PMID_MS) & (Inclusion_SH != inclusion_MS) ~ 'discuss'
  )
)->animal_recoded2 

human_recoded %>% mutate(
  conclusion1= case_when(
    (Reference_PMID_SH!=Reference_PMID_MS) ~'PMIDincor',
    (Reference_PMID_SH==Reference_PMID_MS) &  (inclusion_SH == inclusion_MS) ~ 'same',
    # (Reference_PMID_SH==Reference_PMID_MS) & (inclusion_SH != '?' | inclusion_MS!="?") & (inclusion_SH == inclusion_MS) ~ 'same',
    # (Reference_PMID_SH==Reference_PMID_MS) & (inclusion_SH == '?' | inclusion_MS=="?") ~ 'full_text_check',
    (Reference_PMID_SH==Reference_PMID_MS) & (inclusion_SH != inclusion_MS) ~ 'discuss'
 )
) ->human_recoded2 

# select papers to discuss

# create vectors with PMIDs that need to be discussed:
human_recoded2$Reference_PMID_MS[which(human_recoded2$conclusion=='discuss')]->pmid.h
animal_recoded2$Reference_PMID_MS[which(animal_recoded2$conclusion=='discuss')]->pmid.a

# select original entries for these PMIDs
human_recoded2 %>% filter(Reference_PMID_MS %in% pmid.h) %>% write.csv2(.,file='processed_data/inconsistencies_human_s2.csv')
animal_recoded2 %>% filter(Reference_PMID_MS %in% pmid.a) %>% write.csv2(.,file='processed_data/inconsistencies_animal_s2.csv')

# # upload files to OSF
#   osf_upload(osf_retrieve_node("awkn6"),'processed_data/inconsistencies_human_s2.csv')
#   osf_upload(osf_retrieve_node("awkn6"),'processed_data/inconsistencies_animal_s2.csv')

#remove downloaded files
file.remove(c("data/TRACE_screening_search2_SH.xlsx","data/TRACE_screening_search2_MS.xlsx"))
```

### Step 2: Merge data after discussion inconsistencies ------------------------------
```{r eval=FALSE, include=FALSE}
# 12.5.20

osf_retrieve_file("ugyrp") %>% osf_download(path = "data", conflicts="overwrite") # discussed animal
osf_retrieve_file("kve78") %>% osf_download(path = "data", conflicts="overwrite") # discussed human data

animal_discussed <- read.csv2("data/inconsistencies_animal_s2_SH.csv")
human_discussed <- read.csv2("data/inconsistencies_human_s2_SH.csv")
#remove colums with only na's
human_discussed <- human_discussed[,colSums(is.na(human_discussed))<nrow(human_discussed)]

# human_discussed <- human_discussed[rowSums(is.na(human_discussed))<nrow(human_discussed),]
# animal_discussed <- animal_discussed[rowSums(is.na(animal_discussed))<nrow(animal_discussed),]

# merge columns from discussion to original screening data
animal_discussed %>% select(Reference_PMID_SH,!grep("_SH|_MS", colnames(animal_discussed)))->animal_discussed2
human_discussed %>% select(Reference_PMID_SH,!grep("_SH|_MS", colnames(human_discussed)))->human_discussed2

# merge data
full_join(human_recoded2,human_discussed2, by="Reference_PMID_SH")->human_new
full_join(animal_recoded2,animal_discussed2, by="Reference_PMID_SH")->animal_new


# Create column with new decisions:

# rename "Second.screening..yes...inclusie..no..exlusie....discussieren" to more convenient colname
 colnames(human_new)[40]<-"second.screening"
 colnames(animal_new)[43]<-"second.screening"
 
# new conclusion column human
human_new %>% mutate(
  conclusion2=
    case_when(
      conclusion1 == "same"  ~ inclusion_MS,
      (conclusion1 == "discuss" & (second.screening =="yes"| second.screening =="no")) ~ as.character(second.screening),
      (conclusion1 == "discuss" & (second.screening !="yes"| second.screening !="no")) ~ as.character(Final),
     # (conclusion1 == "discuss" & !is.na(second.screening) & is.na(Final) ) ~ as.character(second.screening),
     # (conclusion1 == "discuss" & !is.na(second.screening) )  ~ as.character(Final))
      )
)->human_new2
# check, there should be no na's
is.na(human_new2$conclusion2) %>% any()

# new conclusion colum human
animal_new %>% mutate(
  conclusion2=
    case_when(
      conclusion1 == "same"  ~ inclusion_MS,
      (conclusion1 == "discuss" & (second.screening =="yes"| second.screening =="no")) ~ as.character(second.screening),
      (conclusion1 == "discuss" & (second.screening !="yes"| second.screening !="no")) ~ as.character(Final),
      # (conclusion1 == "discuss" & !is.na(second.screening) & is.na(Final) ) ~ as.character(second.screening),
      # (conclusion1 == "discuss" & !is.na(second.screening) )  ~ as.character(Final))
    )
)->animal_new2
# check, there should be no na's
is.na(animal_new2$conclusion2) %>% any()

# export new datasets
human_new2 %>% filter(conclusion2 == "?") %>% write.csv2(.,file='processed_data/required_full_checks_human_s2.csv')
animal_new2 %>% filter(conclusion2 == "?") %>% write.csv2(.,file='processed_data/required_full_checks_animal_s2.csv')

# upload files to OSF
 # osf_upload(osf_retrieve_node("awkn6"),'processed_data/required_full_checks_human_s2.csv')
 # osf_upload(osf_retrieve_node("awkn6"),'processed_data/required_full_checks_animal_s2.csv')

#remove downloaded files
file.remove(c("data/inconsistencies_human_s2_SH.csv", "data/inconsistencies_animal_s2_SH.csv"))
```

### Step 3: add information full text screening to data -----------------------------
```{r eval=FALSE, include=FALSE}
#load checked data
osf_retrieve_file("xmua6") %>% osf_download(path = "data", conflicts="overwrite") # full text checks animal animal
osf_retrieve_file("ce35r") %>% osf_download(path = "data", conflicts="overwrite") # full text checks human animal

#read data
animal_full_text <- read.csv2("data/required_full_checks_animal_s2_MS.csv")
# str(animal_full_text)
human_full_text <- read.csv2("data/required_full_checks_human_s2_SH.csv")
# str(human_full_text)

# filter new columns
animal_full_text %>% select(  Reference_PMID_SH, Full_text_MS_notes, Full_text_MS_conclusion )->full.text.checks.animal
human_full_text %>% select(  Reference_PMID_SH, Full_text_SH_notes, Full_text_SH_conclusion )->full.text.checks.human

# merge data
 full_join(human_new2, full.text.checks.human, by="Reference_PMID_SH")->human_screening2_complete
 full_join(animal_new2, full.text.checks.animal, by="Reference_PMID_SH")->animal_screening2_complete
 
 #create variable with final conclusions
 animal_screening2_complete %>% mutate(
   conclusion3=
     case_when(
       conclusion2!= "?" ~ conclusion2,
       conclusion2 == "?"  ~ as.character(Full_text_MS_conclusion)
     )
 )->animal_new3
 
 #checks
is.na(animal_new3$conclusion3) %>% any()
(animal_new3$conclusion3 =="" )  %>% any()

 human_screening2_complete %>% mutate(
   conclusion3=
     case_when(
       conclusion2!= "?" ~ conclusion2,
       conclusion2 == "?"  ~ as.character(Full_text_SH_conclusion)
     )
 )->human_new3
 
# checks
(human_new3$conclusion3 =="")%>% any()
is.na(human_new3$conclusion3) %>% any()

# Overview of inclusions:
animal_new3 %>% filter(conclusion3 == "yes") ->animal_inclusions
human_new3 %>% filter(conclusion3 == "yes") ->human_inclusions


#export data
write.csv2(animal_inclusions,file='processed_data/animal_inclusions_s2.csv')
write.csv2(human_inclusions,file='processed_data/human_inclusions_s2.csv')

# upload files to OSF
# osf_upload(osf_retrieve_node("awkn6"),'processed_data/animal_inclusions_s2.csv')
# osf_upload(osf_retrieve_node("awkn6"),'processed_data/human_inclusions_s2.csv')

 file.remove(c("data/animal_inclusions_s2.csv", "data/human_inclusions_s2.csv"))
```

### For flowchart

#### Total screened
```{r}
# load data
osf_retrieve_file("pu6bf") %>% osf_download(path = "data", conflicts="overwrite")  #abstract screening search2 SH
osf_retrieve_file("56fyu") %>% osf_download(path = "data", conflicts="overwrite")  #abstract screening search2 MS
```

#### Total screened animal
```{r}
SH_animal.S2 <- read_excel("data/TRACE_screening_search2_SH.xlsx", sheet = "screening search 2 animal")
SH_animal.S2[rowSums(is.na(SH_animal.S2)) != ncol(SH_animal.S2), ]->SH_animal.S2 # remove rows with all NA's in screening SH

MS_animal.S2 <- read_excel("data/TRACE_screening_search2_MS.xlsx", sheet = "screening search 2 animal")

nrow(SH_animal.S2)
nrow(MS_animal.S2)
```
```{r} 
# should be identical 
n.s2.A == nrow(MS_animal.S2)
```

#### Total screened human
```{r}
SH_human.S2 <- read_excel("data/TRACE_screening_search2_SH.xlsx", sheet = "screening search 2 human")
SH_human.S2[rowSums(is.na(SH_human.S2)) != ncol(SH_human.S2), ]->SH_human.S2 # remove rows with all NA's in screening SH

MS_human.S2 <- read_excel("data/TRACE_screening_search2_MS.xlsx", sheet = "screening search 2 human")

nrow(SH_human.S2)
nrow(MS_human.S2)
```

```{r} 
# should be identical 
n.s2.H == nrow(MS_human.S2)
```

#### Full text checks animal
```{r}
osf_retrieve_file("xmua6") %>% osf_download(path = "data", conflicts="overwrite") # full text checks animal animal
read.csv2("data/required_full_checks_animal_s2_MS.csv") %>% nrow()
```

#### Full text checks human
```{r}
osf_retrieve_file("ce35r") %>% osf_download(path = "data", conflicts="overwrite") # full text checks human animal
read.csv2("data/required_full_checks_human_s2_SH.csv") %>% nrow()
```
 
 
#### Post-screeing Inclusions animal
```{r}
osf_retrieve_file("m9rey") %>% osf_download(path = "data", conflicts="overwrite") # inclusion s2 (screening) animal
read.csv2("data/animal_inclusions_s2.csv", na.strings = c(" ", "-")) %>% nrow() ->s2.A.n.post.screening
s2.A.n.post.screening
```

#### Post-screeing Inclusions Human
```{r}
osf_retrieve_file("fe5sh") %>% osf_download(path = "data", conflicts="overwrite") # inclusion s2 (screening) human
read.csv2("data/human_inclusions_s2.csv", na.strings = c(" ", "-")) %>% nrow() ->s2.H.n.post.screening
s2.H.n.post.screening
```



#### Inclusions after data-extraction Animal
```{r}
osf_retrieve_file("xqpm3") %>% osf_download(path = "data", conflicts="overwrite") # screening & data extraction S2
read_excel("data/TRACE data_collection_search2.xlsx", sheet = "animal_inclusions_s2")->data.s2.animal

# View(data.s2.animal)
data.s2.animal %>% 
  filter(inclusion.final == 1) %>% 
  # group_by(subject) %>%
    select(`subject`,Reference_PMID_MS ) %>% 
  distinct(Reference_PMID_MS ) %>% tally() -> s2.A.n.in.data
s2.A.n.in.data
```


#### Inclusions after data-extraction Human
```{r}
read_excel("data/TRACE data_collection_search2.xlsx", sheet = "human_inclusions_s2")->data.s2.human

 # str(data.s2.human)
data.s2.human %>% 
  filter(inclusion.final == 1) %>% 
     # group_by(subject) %>%
    select(`subject`,Reference_PMID_MS ) %>% 
  distinct(Reference_PMID_MS ) %>% tally() -> s2.H.n.in.data
s2.H.n.in.data
```

Save inclusions S2 for QA
```{r eval=FALSE, include=FALSE}
data.s2.human %>% filter(inclusion.final == 1) %>% distinct(Reference_PMID_MS ) %>% write.csv2(.,"processed_data/Human.PMIDs.QA.S2.csv")
data.s2.animal %>% filter(inclusion.final == 1) %>% distinct(Reference_PMID_MS) %>% write.csv2(.,"processed_data/Animal.PMIDs.QA.S2.csv")
```


```{r}
file.remove(c("data/required_full_checks_animal_s2_MS.csv", "data/required_full_checks_human_s2_SH.csv",
              "data/animal_inclusions_s2.csv", "data/human_inclusions_s2.csv",
              "data/TRACE data_collection_search2.xlsx"))
```


## S3 screening

### load data
```{r}
osf_retrieve_file("famr7") %>% osf_download(path = "data", conflicts="overwrite") # check screening S3 abstract & full text.

# read_excel("data/Checked_TRACE_screening_search3_MS_EG.xlsx", sheet = "abstract.screening.s3.animal")->abstract.s3.animal
# read_excel("data/Checked_TRACE_screening_search3_MS_EG.xlsx", sheet = "abstract.screening.s3.human")->abstract.s3.human


# Screening_Human (1) of Animal (2) 
# abstract.s3.animal$full.text.check %>% sum()
# str(abstract.s3.human)
```

### Total screened Animal
```{r}
read_excel("data/Checked_TRACE_screening_search3_MS_EG.xlsx", sheet = "full.text.screening.s3.animal")%>%
    filter(!is.na(PMID)) ->s3.animal# to remove last row (with no PMID but total count in excel)
nrow(s3.animal) #254

# s3.animal %>% filter(inclusion.screening != "0") %>% write.csv2(.,file='processed_data/animal.inclusions.s3.csv')
# osf_upload(osf_retrieve_node("e9wmt"),'processed_data/animal.inclusions.s3.csv')
```
```{r}
n.s3.A == nrow(s3.animal) # should be equal
```

### Total screened Human
```{r}
read_excel("data/Checked_TRACE_screening_search3_MS_EG.xlsx", sheet = "full.text.screening.s3.human") %>% 
  filter(!is.na(PMID)) ->s3.human # to remove last row (with no PMID but total count in excel)
nrow(s3.human) # 681

# s3.human %>% filter(inclusion.screening != "0") %>% write.csv2(.,file='processed_data/human.inclusions.s3.csv')
# osf_upload(osf_retrieve_node("e9wmt"),'processed_data/human.inclusions.s3.csv')
```

```{r}
n.s3.H == nrow(s3.human)  #should be equal
```

### Full text checks in screening (animal)
```{r}
s3.animal %>% filter(full.text.checked == 1) %>% nrow()
```


### Full text checks in screening (human)
```{r}
s3.human %>% filter(full.text.checked == 1) %>% nrow()
```

### Inclusions after screening (animal)

```{r}
s3.animal %>% filter(inclusion.screening == "?" )%>% nrow()
```

```{r}
s3.animal %>% 
  # filter(inclusion.screening == 1 ) %>%
  filter(inclusion.screening != 0 ) %>%
nrow() -> s3.A.n.post.screening # NOTE: these include 1 (=inclusion) and ?
s3.A.n.post.screening # 126 without ?
```




### Inclusions after screening (human)

```{r}
s3.human %>%filter(inclusion.screening == "?" ) %>% nrow()
```

```{r}
s3.human %>% 
  # filter(inclusion.screening == 1 ) %>% 
    filter(inclusion.screening != 0 ) %>%
  nrow() -> s3.H.n.post.screening # NOTE: these include 1 (=inclusion) and ?
s3.H.n.post.screening #102 without ?
```




#### Inclusions after data-extraction Animal
```{r}
osf_retrieve_file("wbrcm") %>% osf_download(path = "data", conflicts="overwrite") # screening & data extraction S1
read_excel("data/TRACE_data_collection_search3.xlsx", sheet = "animal.inclusions.s3")->data.s3.animal

# str(data.s3.animal)
data.s3.animal %>% 
  filter(inclusion.final == 1) %>% 
      # group_by(subject) %>% # to split by rat and mice
    select(`subject`,PMID ) %>% 
  distinct(PMID) %>% tally() -> s3.A.n.in.data
s3.A.n.in.data
```


```{r}
68+18
```

#### Inclusions after data-extraction human
```{r}
read_excel("data/TRACE_data_collection_search3.xlsx", sheet = "human.inclusions.s3")->data.s3.human

data.s3.human %>% 
  filter(inclusion.final == 1) %>% 
    # group_by(subject) %>%
    select(`subject`,PMID ) %>% 
  distinct(PMID) %>% tally() -> s3.H.n.in.data  #indeed same numbers as with files above
s3.H.n.in.data
```
Save inclusions S3 for QA
```{r eval=FALSE, include=FALSE}
# data.s3.human %>% filter(inclusion.final != 0)%>% distinct(PMID) #same
# data.s3.animal %>% filter(inclusion.final != 0)%>% distinct(PMID) # same

data.s3.human %>% filter(inclusion.final == 1) %>% distinct(PMID) %>% write.csv2(.,"processed_data/Human.PMIDs.QA.S3.csv")
data.s3.animal %>% filter(inclusion.final == 1) %>% distinct(PMID) %>% write.csv2(.,"processed_data/Animal.PMIDs.QA.S3.csv")
```


```{r}
file.remove(c("data/TRACE_data_collection_search3.xlsx"))
```

# Total screened in S1,S2,S3

## Clinical
```{r}
292+142+681 == 
  total.screened.clinical
```

## preclinical 
```{r}
178+114+254 == total.screened.preclinical
```

# total in included in dataset
(subject 1 = human, subject 2 = preclinical)
clinical
```{r}
s1.n.in.data %>% filter(subject ==1) %>% select(n) +
  s2.H.n.in.data +
  s3.H.n.in.data
```
preclinical
```{r}
s1.n.in.data %>% filter(subject ==2) %>% select(n) +
    s2.A.n.in.data +
  s3.A.n.in.data
```
double check if numbers above are same as in prepared data (yes)
```{r}
readRDS("processed_data/TRACEprepared.RData")->dataset

dataset %>% group_by(subject.cat) %>%
  summarize(papers=length(unique(PMID)), 
            groups=length(unique(new.idPTSD)),
            comparisons=length(each)) %>% data.frame()-> combined.n.in.data
combined.n.in.data
```


# Create flowchart

```{r}
library(grid)
library(Gmisc)
```

create summary var's for flowchart

```{r}
total.screened.clinical+total.screened.preclinical -> total.screened
#human
s1.n.post.screening[1,2]+s2.H.n.post.screening+s3.H.n.post.screening ->post.screening.H
  #animal
s1.n.post.screening[2,2]+s2.A.n.post.screening+s3.A.n.post.screening-> post.screening.A


post.screening.H$n +post.screening.A$n ->post.screening
combined.n.in.data[1,2] ->included.A
combined.n.in.data[2,2]->included.H
included.A+included.H->included

# number of unique subjects in PTSD group
dataset %>% 
  distinct(new.idPTSD, .keep_all = TRUE) %>% 
   # group_by(subject, sex.PTSD) %>%
     group_by(subject.cat) %>%
  # group_by(subject) %>%  
  tally(round(nPTSD,0)) ->unique.n.PTSD.subjects


# papers in final theoretical analysis
# lood prepared data for descriptives (export created in analysis scripts theoretical and data-driven analysis)
readRDS("processed_data/clinical.data.metaregression.RDS") %>% 
  summarize(#papers=length(unique(PMID)), 
            groups=length(unique(new.idPTSD))#,
            # comparisons=length(each)
            ) %>% data.frame()->metaregression.clinical
metaregression.clinical
# metaregression.clinical %>% distinct(new.idPTSD, .keep_all = TRUE) %>% nrow() # idem

readRDS("processed_data/preclinical.data.metaregression.RDS")%>% 
  summarize(#papers=length(unique(PMID)), 
            groups=length(unique(new.idPTSD))#,
            # comparisons=length(each)
            ) %>% data.frame()->metaregression.preclinical
metaregression.preclinical

# pmid not present in data
readRDS("processed_data/clinical.data.explorative.RDS")%>%
  summarize(
    # papers=length(unique(PMID)),
            groups=length(unique(new.idPTSD))#,
            # comparisons=length(each)
            ) %>% data.frame()->metaforest.clinical
metaforest.clinical

readRDS("processed_data/preclinical.data.explorative.RDS")%>%
  summarize(
    # papers=length(unique(PMID)),
            groups=length(unique(new.idPTSD))#,
            # comparisons=length(each)
            ) %>% data.frame()->metaforest.preclinical
metaforest.preclinical$groups

# same number of independent ptsd groups included in metaregression, metaforest/metacart?
metaforest.preclinical$groups == metaregression.preclinical$groups # yes
metaforest.clinical$groups == metaregression.clinical$groups # yes
```

# create flowchart

https://www.r-bloggers.com/2018/05/flow-charts-in-r/
```{r}
  jpeg(file="results/flowchart.jpeg", height = 2200, width = 2500, res=300)

grid.newpage()
# set some parameters to use repeatedly
leftx <- .35
midx <- .5
rightx <- .65
width <- .2
gp <- gpar(fill = "lightgrey")
# create boxes
(total <- boxGrob(paste0("Screened Records\n N =",total.screened), 
 x=midx, y=.9, box_gp = gp, width = width))

# (rando <- boxGrob("Randomized\n N = NNN", 
#  x=midx, y=.75, box_gp = gp, width = width))
# # connect boxes like this
# connectGrob(total, rando, "v")



(g1 <- boxGrob(paste0("Screened clinical\n studies N = ",total.screened.clinical), 
 x=leftx, y=.7, box_gp = gp, width = width))
(g2 <- boxGrob(paste0("Screened preclinical\n studies N = ",total.screened.preclinical), 
 x=rightx, y=.7, box_gp = gp, width = width))

connectGrob(total, g1, "N")
connectGrob(total, g2, "N")


(inel.cl1 <- boxGrob(paste0("Exclusions\n N = ",total.screened.clinical-post.screening.H$n),
 x=.15, y=.625, box_gp = gp, width = .125, height = .06))

(inel.precl1 <- boxGrob(paste0("Exclusions\n N = ",total.screened.preclinical-post.screening.A$n),
 x=.85, y=.625, box_gp = gp, width = .125, height = .06))

connectGrob(g1, inel.cl1, "-")
connectGrob(g2, inel.precl1, "-")


(g11 <- boxGrob(paste0("Eligible clinical\n studies N = ",post.screening.H$n),
 x=leftx, y=.525, box_gp = gp, width = width))
(g21 <- boxGrob(paste0("Eligible preclinical\n studies N = ",post.screening.A$n),
 x=rightx, y=.525, box_gp = gp, width = width))
# 
connectGrob(g1, g11, "N")
connectGrob(g2, g21, "N")

(inel.cl2 <- boxGrob(paste0("Exclusions\n N = ",post.screening.H$n-combined.n.in.data[2,2]),
 x=.1, y=.45, box_gp = gp, width = .125, height = .06))

(inel.precl2 <- boxGrob(paste0("Exclusions\n N = ",post.screening.A$n-combined.n.in.data[1,2]),
 x=.9, y=.45, box_gp = gp, width = .125, height = .06))

connectGrob(g11, inel.cl2, "-")
connectGrob(g21, inel.precl2, "-")

(g12 <- boxGrob(paste0("Included clinical\n studies N=", combined.n.in.data[2,2],":\n- ", 
                       combined.n.in.data[2,4] ," comparisons\n- ", 
                       combined.n.in.data[2,3] ," independent patient groups\n- ", 
                       unique.n.PTSD.subjects[2,2]," unique patients"), 
 x=leftx, y=.3, box_gp = gp, width = width+0.09))
(g22 <- boxGrob(paste0("Included preclinical\n studies N=", combined.n.in.data[1,2],":\n- ", 
                       combined.n.in.data[1,4] ," comparisons\n- ", 
                       combined.n.in.data[1,3] ," independent PTSD groups\n- ", 
                       unique.n.PTSD.subjects[1,2]," unique PTSD animals"), 
 x=rightx, y=.3, box_gp = gp, width = width+0.09))

connectGrob(g11, g12, "N")
connectGrob(g21, g22, "N")


(g13 <- boxGrob(paste0("independent patient groups \nin meta-analysis N = ",metaregression.clinical$groups),
 x=leftx, y=.1, box_gp = gp, width = width+0.09))

(g23 <- boxGrob(paste0("independent PTSD groups \nin meta-analysis N = ",metaregression.preclinical$groups),
 x=rightx, y=.1, box_gp = gp, width = width+0.09))

connectGrob(g12, g13, "N")
connectGrob(g22, g23, "N")

  dev.off()
```

https://cran.r-project.org/web/packages/PRISMAstatement/vignettes/PRISMA.html
```{r}
# install.packages("PRISMAstatement")
library(PRISMAstatement)

prisma(found = total.screened,
       found_other = 0,
       no_dupes = total.screened, 
       screened = total.screened, 
       screen_exclusions = total.screened-post.screening,
       full_text = post.screening,
       full_text_exclusions = post.screening-included, 
       qualitative = included, 
       quantitative = included,
       width = 400, height = 800)
```

