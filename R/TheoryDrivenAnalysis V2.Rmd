---
title: "Theory-driven meta-analysis TRACE"
author: "Milou Sep"
date: "4/27/2021"
output:
  html_document: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

# Analysis script for TRACE analyses (based on analyses script Valeria (meta behavior))
Code largely based on // adapted from Bonapersona, V. (2019, May 20). The behavioral phenotype of early life adversity: a 3-level meta-analysis of rodent studies. Retrieved from osf.io/ra947


## Environment Preparation
```{r setup, include=FALSE}
rm(list = ls()) #clean environment
# libraries
library(dplyr) #general
library(ggplot2) #for graphs
library(metafor) #for meta-analysis
library(ggpubr) # To show multiple plots in 1 figure
library("viridis")   # ggplot colours
library(flextable) # to create tables
library(officer)# to export tables to word
```

## Import dataset 
(processed with merge_datasets.rmd, recode_merged_data.rmd, add_effect_size_QA.rmd)
```{r}
data<-readRDS("processed_data/TRACEprepared.RData")
```

In check_comparison.rmd script frequency of observations in groups checked

## Split clinical and preclinical data
- Clinical and preclinical data are analyzed as two separate datasets 
- comparison "B" is excluded from clinical data as it does not contain PTSD-patients 

[A= non-exposed vs trauma-exposed PTSD (human); B=non-exposed vs trauma exposed no PTSD (human); C=trauma-exposed (noPTSD) vs trauma-exposed PTSD (human); D=non-exposed vs trauma-exposed (no PTSD checked) (animal); E=non-exposed vs trauma-exposed PTSD (animal); F=trauma-exposed (no ptsd) vs trauma-exposed PTSD (animal)]

```{r}
# Clinical data 
data %>% 
  filter(subject.cat =="Human") %>% 
  filter(comparison !="B") %>%
  droplevels() ->clinical

# Preclinical data 
data %>% 
  filter(subject.cat =="Animal") %>% 
  droplevels() ->preclinical
```

## Remove subgroups with < 4 papers from analyses (by removal of data)

### Clinical
```{r}
clinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
clinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% 
  filter(papers <4) %>% 
  mutate(
    phase.valence.code = paste(phase, valence,sep=".")
  ) ->excluded.levels.human

excluded.levels.human
```

```{r}
clinical %>% 
  mutate(phase.valence.code = paste(phase, valence,sep=".")) ->clinical1
clinical1 %>% 
  filter(!(phase.valence.code %in% excluded.levels.human$phase.valence.code)) %>% droplevels() -> clinical.filtered
```

```{r}
# for checking (should be total numbers of papers above, so here 4)
clinical1 %>% filter((phase.valence.code %in% excluded.levels.human$phase.valence.code)) %>% distinct(PMID)
```

### Preclinical
```{r}
preclinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each))
```

```{r}
preclinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% 
  filter(papers <4) %>% 
  mutate(
    phase.valence.code = paste(phase, valence,sep=".")
  ) ->excluded.levels.animal

excluded.levels.animal
```

> no exclusions needed in preclinial data (levels >=4 papers)

# multilevel models

## Research Question 1: Learning and Memory of stressful and non-stressful information in PTSD patients

### Model - unfilterd data
```{r}
mod.clinical.total <- rma.mv(yi, vi,
                             random = list(~1 | new.idPTSD , ~1 | PMID),  # valeria had each.. ik heb in oic meta PMID.. results ong same maar beetje anders -> volgens mij is PMID de bedoeling
                             # random = list(~1 | PMID , ~1 | new.idPTSD),  # just for checking -> es expacted exactly the same estimaes
                             # random = ~ 1 | new.idPTSD / each,  # identical results as row above  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/fitting-a-three-level-model.html
                             # mods   = ~phase.valence - 1,
                             # mods = ~Valence_Grouped:phase-1, # all impaired  (NB E, F and T were grouped as emotional)
                             mods = ~valence:phase-1, # fear ext and fear memory impoved (trauma m NS), rest impaired
                             method = "REML",
                             slab = clinical$reference,  # from old codes milou (change for author/year)
                             data = clinical) # Similar effects with dat2 (trauma learning excluded)
summary(mod.clinical.total)
```

### Model - filtered data
```{r}
mod.clinical <- rma.mv(yi, vi,
                       random = list(~1 | new.idPTSD , ~1 | PMID),  # valeria had each.. ik heb in oic meta PMID.. results ong same maar beetje anders -> volgens mij is PMID de bedoeling
                       # random = ~ 1 | new.idPTSD / each,  # identical results as row above  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/fitting-a-three-level-model.html
                       # mods   = ~phase.valence - 1,
                       # mods = ~Valence_Grouped:phase-1, # all impaired  (NB E, F and T were grouped as emotional)
                       mods = ~valence:phase-1, # fear ext and fear memory impoved (trauma m NS), rest impaired
                       method = "REML",
                       slab = clinical.filtered$reference,  # from old codes milou (change for author/year)
                       data = clinical.filtered) # Similar effects with dat2 (trauma learning excluded)
summary(mod.clinical)
```

### add contrasts
```{r}
TRACE_clinical_valence_phase <- function(model){

  # some info: Test linear combinations (http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms)
  # http://www.metafor-project.org/doku.php/tips:multiple_factors_interactions

 extinction <- anova(model, L = c(1,0, 0, 0,0))
  fearLearning <- anova(model, L = c(0,1, 0, 0,0))
  neutralLearning <- anova(model, L = c(0,0, 1, 0,0))
  emotionalMemory <- anova(model, L = c(0,0, 0, 1,0))
  neutralMemory <- anova(model, L = c(0,0, 0, 0, 1))
  
  
  # Posthoc RQ2 influence of valence on learning or memory
  valence.learning <-anova(model, L = c(0, 1, -1, 0,0)) # neutral = -
  valence.memory <- anova(model, L = c(0,0,0, 1, -1))
  
  
  ##Summary results organized in table
  resultMain <- data.frame(matrix(data = NA, nrow = 7, ncol = 8)) #V new
  
  colnames(resultMain) <- c("test", "effectsize", "se", "ci.lb", "ci.ub", "Zvalue", "Pvalue", "Pvalue_bonfCorr")
  
  resultMain[,1] <- c( "neutral Learning", "neutral Memory", "fear Learning", "emotional Memory", "fear Extinction",
    "valence.learning: neutral vs emotional (learning)", "valence.memory: neutral vs emotional (memory)")
  
  resultMain[,2] <- round(c(
    neutralLearning$Lb, neutralMemory$Lb,
    fearLearning$Lb, emotionalMemory$Lb,
    extinction$Lb,
        valence.learning$Lb, valence.memory$Lb
  ), digits = 4) #effect size
  
  resultMain[,3] <- round(c( neutralLearning$se, neutralMemory$se,
    fearLearning$se, emotionalMemory$se,
    extinction$se,
      valence.learning$se, valence.memory$se
  ), digits = 4) #se
  
  resultMain[,4] <- round(resultMain[,2] - (resultMain[,3] * 1.96), digits = 4) #CI lower 
  resultMain[,5] <- round(resultMain[,2] + (resultMain[,3] * 1.96), digits = 4) #CI upper
  
  resultMain[,6] <- round(c(
    neutralLearning$zval, neutralMemory$zval,
    fearLearning$zval, emotionalMemory$zval,
    extinction$zval,
 valence.learning$zval, valence.memory$zval
  ), digits = 4)  #zvalues
  
  resultMain[,7] <- round(c(
    neutralLearning$pval, neutralMemory$pval,
    fearLearning$pval, emotionalMemory$pval,
    extinction$pval,
valence.learning$pval, valence.memory$pval
  ), digits = 4)  #pvalues

  resultMain[,8] <- round(p.adjust(resultMain[,7], method = "bonferroni", n = 7), digits = 4) #pvalue bonf correction
  
  return(resultMain)
  
}

TRACE_clinical_valence_phase(mod.clinical)->clinical.results
```

### create plot
```{r}
clinical.results %>% 
  filter(test %in% c( "neutral Learning", "neutral Memory", "fear Learning", "emotional Memory", "fear Extinction")) %>% 
  mutate(
    valence = ifelse(test %in% c("neutral Learning", "neutral Memory"), "Neutral", "Emotional"),
    phase = case_when(
      test %in% c( "neutral Learning", "fear Learning") ~ "Learning", 
      test %in% c( "neutral Memory", "emotional Memory") ~ "Memory", 
      test == "fear Extinction" ~ "Extinction"
    ),
    # phase = factor(phase, levels = c("Learning", "Memory", "Extinction"))  # dan error with plot
    
    # signal sig. categories. Add index for p-values smaller than 0.05
    sig =ifelse(Pvalue_bonfCorr<0.05, 1, 0),
    
    valence= factor(valence, levels =c("Neutral", "Emotional")),
    # plot_data_coded$test = factor(plot_data_coded$test)
    test = factor(test, levels = c("neutral Learning", "fear Learning", "neutral Memory", "emotional Memory", "fear Extinction")#,
                  # labels = c("neutral", "fear", "neutral", "emotional", "fear")
    )
  ) ->clinical_plot_data_coded


# plot_data_coded$sig<- ifelse(plot_data_coded$Pvalue_bonfCorr  <0.05, 1, 0)


# https://www.datanovia.com/en/blog/ggpubr-how-to-add-p-values-generated-elsewhere-to-a-ggplot/

clinical.results %>% 
  select(test,p=Pvalue_bonfCorr) %>% 
  filter(grepl("valence",test,fixed = T)) %>% 
  mutate(
    group1 = case_when(
      # grepl("phase.neutral",test) ~ "neutral Learning",
      #   grepl("phase.emotional",test) ~ "fear Learning"#,
      
      grepl("valence.learning",test) ~ "neutral Learning",
      grepl("valence.memory",test) ~ "neutral Memory"
    ),
    
    group2 = case_when(
      # grepl("phase.neutral",test) ~ "neutral Memory",
      # grepl("phase.emotional",test) ~ "emotional Memory"#,
      
      grepl("valence.learning",test) ~ "fear Learning",
      grepl("valence.memory",test) ~ "emotional Memory"
    ),
    
    phase = 
      case_when(
        grepl("learning",test) ~ "Learning",
        grepl("memory",test) ~ "Memory"),
    # c( "Learning", "Memory"),
    p.adj = ifelse(p == 0, yes = "p<.001", no = paste0("p=",round(p,3)))
    # valence = c("Neutral", "Emotional", NA, NA)
  ) %>% group_by(phase)-> clinical.posthoc.valence


# plot_data_coded$valence= factor(plot_data_coded$valence, levels =c("Neutral", "Emotional"))
# # plot_data_coded$test = factor(plot_data_coded$test)
# plot_data_coded$test = factor(plot_data_coded$test, levels = c("neutral Learning", "fear Learning", "neutral Memory", "emotional Memory", "fear Extinction")#,
#                               # labels = c("neutral", "fear", "neutral", "emotional", "fear")
# )


PLOT.clinical <-
  ggplot(clinical_plot_data_coded,
         aes(x = test, y = effectsize, fill=valence)) +
  labs(
     title = "A) Clinical Data: PTSD patients",
    # subtitle = "PTSD patients",
    y="Hedge's G (95%CI)", # could also be "Standardized mean difference"
    x="") + 
  facet_grid (.~ factor(phase, levels =c("Learning", "Memory", "Extinction")),  # width scaled (better for extinction)
              scales = "free_x", space = "free_x", switch = "x" # labels onder
              # je kan de andere factor levels nog toevoegen en dan hier drop =F, bv voor het vergelijkbaar maken met dieren?
  ) +
  # theme_linedraw() +
   theme_pubr(base_size = 12)+
  
  # theme(plot.title = element_text(hjust = 0.5)) +
  # theme(plot.subtitle = element_text(hjust = 0.5, face="italic")) +
  # scale_fill_manual(
  #   values= c( "Neutral" = "steelblue2", # Colours: http://sape.inf.usi.ch/quick-reference/ggplot2/colour
  #              "Emotional" = "tomato2")) +

       scale_fill_viridis(discrete = TRUE, #begin = 0.1, end = 0.9 , 
                          option = "cividis") +
  
  
  geom_bar(stat = "identity")+
  geom_hline(yintercept = 0, size = 1) +
  geom_errorbar(aes(ymin = ci.lb,
                    ymax = ci.ub),
                width = .3) +
  # theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  
  # sig marks
  geom_point(data = clinical_plot_data_coded[clinical_plot_data_coded$sig ==1, ],aes(x=test, y=1), shape = "*", size=10, show.legend = FALSE) +  # to make position dynamic use: y=ci.ub+1.5
  
  # y_sig_position <- 1 #  ifelse(title=='Clinical Data', 1  , 3.3 )
  #  title='Preclinical Data'
  
  ggpubr::stat_pvalue_manual( data.frame(clinical.posthoc.valence), inherit.aes=F,
                              y.position = 0.3, 
                              # label = "p = {round(p,3)}", 
                              label =  "p.adj",
                              
                              size=4) +
  
  scale_x_discrete(labels=c("neutral Learning" = "neutral", 
                            "fear Learning" = "fear",
                            "neutral Memory" = "neutral",
                            "emotional Memory" = "emotional",
                            "fear Extinction" = "fear"))

PLOT.clinical
```

### save data table
```{r}
clinical.results[,2:8]<-round(clinical.results[,2:8],3)
# correct pvalue 0
clinical.results %>% mutate(
  Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue),
  Pvalue_bonfCorr = ifelse(Pvalue_bonfCorr == 0, "<.001", Pvalue_bonfCorr))->clinical.results

write.csv2(clinical.results, "results/phase_valence_PTSD_clinical.csv")
```


### Save plot
```{r}
ggsave(paste0("results/phase_valence_PTSD_clinical", #date(),
              ".jpg"),
       plot=PLOT.clinical+  theme(text = element_text(size = 12)),
       device="jpg", dpi = 300, units = "cm", height = 10, width = 15, limitsize = T )

# jpeg(file="results/clinical.jpeg", height = 2000, width = 1500, res=300)
# clinical.results[[2]]
# dev.off()
```

```{r eval=FALSE, fig.height=40, fig.width=8, include=FALSE}
forest(mod.clinical, cex = .2)
# clinical %>% filter(yi > 4) %>% View()
# clinical %>% filter(measure.d == "EXT_%CS+/maxCS+Acq_EMG") %>% View()
```


### Diagnostics clinical

#### Heterogeneity
out oic meta code
"The I² statistic was used to assess heterogeneity of effect sizes. According to Higgins et al. (2003) values of 25, 50 and 75% are indicative of low, moderate and high heterogeneity, respectively. Rosenthal’s fail-safe N was used to assess the robustness of effect sizes. Fail-safe N determines the number of studies with effect size 0 that would be necessary to cancel out significant effect sizes. Effect sizes were considered robust when N values>5k + 10, where k refers to the number of studies used in the meta-analysis (Rosenthal, 1995). The possibility of publication bias was also assessed by Egger Funnel plot asymmetry (Egger et al., 1997) and all reported significance tests were two tailed with α = .05." [Sep MSC, Steenmeijer A, Kennis M. The relation between anxious personality traits and fear generalization in healthy subjects: A systematic review and meta-analysis. Neurosci Biobehav Rev 2019; 107: 320–328.]


```{r}
# heterogeneity from multilevel model
# heterogeneity (i2)
# http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
# dat=data6
Wc <- diag(1/clinical.filtered$vi)
Xc <- model.matrix(mod.clinical)
Pc <- Wc - Wc %*% Xc %*% solve(t(Xc) %*% Wc %*% Xc) %*% t(Xc) %*% Wc
100 * sum(mod.clinical$sigma2) / (sum(mod.clinical$sigma2) + (mod.clinical$k-mod.clinical$p)/sum(diag(Pc)))
```


```{r}
# between & within variance
100 * mod.clinical$sigma2 / (sum(mod.clinical$sigma2) + (mod.clinical$k-mod.clinical$p)/sum(diag(Pc)))
# sig 2.1 -> variance in xperimental group
# 8.55% within study ( experimental group) 75,4% between study ( PMID)
```


#### Publication bias: funnel

https://rdrr.io/cran/metafor/man/funnel.html: 
- "For models involving moderators, the plot shows the residuals on the x-axis against their corresponding standard errors."
- "For fixed- and random-effects models (i.e., models not involving moderators), the plot shows the individual observed effect sizes or outcomes on the x-axis against the corresponding standard errors (i.e., the square root of the sampling variances) on the y-axis"

```{r}
funnel(mod.clinical, legend = F, col=clinical.filtered$PMID, 
       back = 'white') 
```

```{r}
tiff(file="results/funnel.colours.clinical.tiff", height=1000, width=1000, pointsize=6, res=300)
funnel(mod.clinical, legend = F, col=clinical.filtered$PMID, 
       back = 'white') 
dev.off()
```

#### robustness of effect
```{r}
mod.clinical.bias <- rma.uni(yi, vi,
                             # random = list(~1 | new.idPTSD , ~1 | PMID),
                             mods = ~valence:phase-1,
                             method = "REML",
                             slab = clinical.filtered$reference, 
                             data = clinical.filtered) 
# summary(mod.preclinical.bias)
```

##### Egger's regression
```{r}
regtest(mod.clinical.bias, ret.fit = TRUE) # Egger's regression random effects (mixed not available)
```

##### Begg's test
```{r eval=FALSE, include=FALSE}
regtest(clinical.filtered$yi, clinical.filtered$vi)
```

##### file drawer analysis (fail and safe)
```{r eval=FALSE, include=FALSE}
fsn(yi = yi, vi = vi, 
    data = clinical.filtered, type = "Rosenthal")
```

file drawer analysis is performed within valence x phase subgroups

```{r}
fsn.table.clincal <- data.frame(matrix(data = NA, nrow = 5, ncol = 4)) #V new

names(fsn.table.clincal)<-c("valence", "phase", "Fail-save N", "Pvalue")

fsn(yi = yi, vi = vi, 
    data = clinical.filtered, 
    subset = (clinical.filtered$valence == "F" & clinical.filtered$phase == "E"),
    type = "Rosenthal") ->fsnFE.clinical
fsnFE.clinical
fsn.table.clincal[1,] <- c("F", "E", fsnFE.clinical$fsnum, fsnFE.clinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = clinical.filtered, 
    subset = (clinical.filtered$valence == "F" & clinical.filtered$phase == "L"),
    type = "Rosenthal") ->fsnFL.clinical
fsnFL.clinical
fsn.table.clincal[2,] <- c("F", "L", fsnFL.clinical$fsnum, fsnFL.clinical$pval)
```


```{r}
fsn(yi = yi, vi = vi,
    data = clinical.filtered,
    subset = (clinical.filtered$valence == "N" & clinical.filtered$phase == "L"),
    type = "Rosenthal") ->fsnNL.clinical
fsnNL.clinical
fsn.table.clincal[3,] <- c("N", "L", fsnNL.clinical$fsnum, fsnNL.clinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = clinical.filtered, 
    subset = (clinical.filtered$valence == "E" & clinical.filtered$phase == "M"),
    type = "Rosenthal") ->fsnEM.clinical
fsnEM.clinical
fsn.table.clincal[4,] <- c("E", "M", fsnEM.clinical$fsnum, fsnEM.clinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = clinical.filtered, 
    subset = (clinical.filtered$valence == "N" & clinical.filtered$phase == "M"),
    type = "Rosenthal") ->fsnNM.clinical
fsnNM.clinical
fsn.table.clincal[5,] <- c("N", "M", fsnNM.clinical$fsnum, fsnNM.clinical$pval)
```

###### view and save complete table
```{r}
fsn.table.clincal$Pvalue <- round(as.numeric(fsn.table.clincal$Pvalue),3)
fsn.table.clincal$Pvalue<- ifelse(fsn.table.clincal$Pvalue == 0, "<.001",fsn.table.clincal$Pvalue)

fsn.table.clincal

write.csv2(fsn.table.clincal, "results/phase_valence_PTSD_clinical.FSN.csv")
```

##### trim and fill
only available for model without moderators, since moderation is present.. not valid test for robustness of the effects?
```{r eval=FALSE, include=FALSE}
mod.clinical.bias2 <- rma.uni(yi, vi,
                              # random = list(~1 | new.idPTSD , ~1 | PMID),
                              #mods = ~valence:phase-1,
                              method = "REML",
                              slab = clinical.filtered$reference, 
                              data = clinical.filtered) 
# funnel(mod.clinical.bias2)
trimfill(mod.clinical.bias2) 
```


### Sensitivity analysis clinical

#### study quality
```{r}
mod.clinical.QA <- rma.mv(yi, vi,
                          random = list(~1 | new.idPTSD , ~1 | PMID),  
                          # mods = ~valence:phase-1, 
                          mods = ~RoB_score,#*valence:phase-1,  # valeria doet ook alleen 'blinding and randomized variable as moderator in model"
                          method = "REML",
                          slab = clinical.filtered$reference, 
                          data = clinical.filtered) 
summary(mod.clinical.QA)
```


#### Influential cases
phase x valence meta-regression without cases that were identified as influential & outlier -> for sensitivity analysis
```{r}
source("R/influentials_valence_phase.R")
```

```{r eval=FALSE, include=FALSE}
clinical.inf<-influentials_valence_phase(clinical.filtered)
saveRDS(clinical.inf, "processed_data/influentials.clinical.rds")
```

```{r}
readRDS("processed_data/influentials.clinical.rds")->clinical.inf
```

potential outlier and influential cases
```{r}
clinical.inf[which(clinical.inf$outInf == 1),] %>% nrow()
```

studies with potential outlier and influential cases
```{r}
clinical.inf[which(clinical.inf$outInf == 1),]%>% distinct(PMID) %>% nrow()
```

remove outliers + influential (Viechtbauer & Cheung) 
```{r}
clinical.inf %>%
  filter(outInf != 1) %>%
  droplevels() -> clinical.noinfout
```

model without potential outliers + infuential cases
```{r}
mod.clinical.noinf <- rma.mv(yi, vi,
                             random = list(~1 | new.idPTSD , ~1 | PMID),  
                             mods = ~valence:phase-1, 
                             method = "REML",
                             slab = clinical.noinfout$reference,  # from old codes milou (change for author/year)
                             data = clinical.noinfout) # Similar effects with dat2 (trauma learning excluded)

summary(mod.clinical.noinf)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.clinical.noinf$b),
        round(
                 data.frame(
                 mod.clinical.noinf$b, mod.clinical.noinf$se, 
                 mod.clinical.noinf$ci.lb, mod.clinical.noinf$ci.ub, 
                 mod.clinical.noinf$zval, mod.clinical.noinf$pval,row.names = NULL), 
                 3)
  ) ->sens.infout.clinical.results

colnames(sens.infout.clinical.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
sens.infout.clinical.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->sens.infout.clinical.results2

write.csv2(sens.infout.clinical.results2,"results/sens.clinical.infout.csv")
```


#### comparision types

##### A non-trauma exposed vs PTSD
[A= non-exposed vs trauma-exposed PTSD (human); 
E=non-exposed vs trauma-exposed PTSD (animal)
```{r}
# Clinical data 
data %>% 
  filter(subject.cat =="Human") %>% 
  filter(comparison =="A") %>%
  droplevels() ->clinical.filtered.HC.PTSD

clinical.filtered.HC.PTSD %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~valence:phase-1,
       method = "REML",
       slab = clinical.filtered.HC.PTSD$reference,
       data = clinical.filtered.HC.PTSD) ->mod.A
summary(mod.A)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.A$b),
        round(
                 data.frame(
                 mod.A$b, mod.A$se, 
                 mod.A$ci.lb, mod.A$ci.ub, 
                 mod.A$zval, mod.A$pval,row.names = NULL), 
                 3)
  ) ->mod.A.results

colnames(mod.A.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
mod.A.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->mod.A.results2

write.csv2(mod.A.results2,"results/sens.mod.A.csv")
```


##### B non-trauma exposed vs trauma-exposed HC
B=non-exposed vs trauma exposed no PTSD (human); 
D=non-exposed vs trauma-exposed (no PTSD checked) (animal)
```{r}
# Clinical data 
data %>% 
  filter(subject.cat =="Human") %>% 
  filter(comparison =="B") %>% 
  droplevels() ->clinical.filtered.HC.TC

clinical.filtered.HC.TC %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r eval=FALSE, include=FALSE}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~valence:phase-1,
       method = "REML",
       slab = clinical.filtered.HC.TC$reference,
       data = clinical.filtered.HC.TC) %>% summary()
```

> Only one level of valence (Neutral) is available for comparision B, therefore valence excluded from this model

NOTE, model below contains only neutral valence
```{r}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~phase-1,
       method = "REML",
       slab = clinical.filtered.HC.TC$reference,
       data = clinical.filtered.HC.TC) ->mod.B

summary(mod.B)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.B$b),
        round(
                 data.frame(
                 mod.B$b, mod.B$se, 
                 mod.B$ci.lb, mod.B$ci.ub, 
                 mod.B$zval, mod.B$pval,row.names = NULL), 
                 3)
  ) ->mod.B.results

colnames(mod.B.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
mod.B.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->mod.B.results2

write.csv2(mod.B.results2,"results/sens.mod.B.csv")
```


##### C trauma exposed vs PTSD
C=trauma-exposed (noPTSD) vs trauma-exposed PTSD (human);
F=trauma-exposed (no ptsd) vs trauma-exposed PTSD (animal)]
```{r}
# Clinical data 
data %>% 
  filter(subject.cat =="Human") %>% 
  filter(comparison =="C") %>%
  droplevels() ->clinical.filtered.TC.PTSD

clinical.filtered.TC.PTSD %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~valence:phase-1,
       method = "REML",
       slab = clinical.filtered.TC.PTSD$reference,
       data = clinical.filtered.TC.PTSD) -> mod.C
summary(mod.C)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.C$b),
        round(
                 data.frame(
                 mod.C$b, mod.C$se, 
                 mod.C$ci.lb, mod.C$ci.ub, 
                 mod.C$zval, mod.C$pval,row.names = NULL), 
                 3)
  ) ->mod.C.results

colnames(mod.C.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
mod.C.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->mod.C.results2

write.csv2(mod.C.results2,"results/sens.mod.C.csv")
```

## Research Question 2: Learning and Memory of emotional and non-emotional information in animal models of PTSD

### Model
```{r}
mod.preclinical <- rma.mv(yi, vi,
                          random = list(~1 | new.idPTSD , ~1 | PMID),
                          mods = ~valence:phase-1,
                          method = "REML",
                          slab = preclinical$reference, 
                          data = preclinical) 
summary(mod.preclinical)
```

```{r eval=FALSE, fig.height=80, fig.width=8, include=FALSE}
forest(mod.preclinical, cex = 0.4)
```

### add contrasts
```{r}
TRACE_preclinical_valence_phase <- function(model){
  
  fearExtinction <- anova(model, L = c(1,0, 0, 0,0,0,0))
  traumaExtinction <-anova(model, L = c(0,1, 0, 0,0,0,0))
  
  fearLearning <- anova(model, L = c(0,0,1, 0,0,0,0))
  neutralLearning <- anova(model, L = c(0,0,0, 1, 0,0,0))
  # emotionalMemory <- anova(model, L = c(0,0, 0, 1,0,0,0))
  fearMemory <- anova(model, L = c(0,0, 0,0,1,0,0))
  neutralMemory <- anova(model, L = c(0,0, 0, 0, 0,1,0))
  traumaMemory <- anova(model, L = c(0,0, 0, 0, 0,0,1))
  
    valence.learning <-anova(model, L = c(0,0,1,-1,
                                        0,0,0)) # neutral (-) vs fear learning

  valence.memory.NF <- anova(model, L = c(0,0,0,0, # neutral (-) vs fear memory
                                          1,-1, 0))
  
  valence.memory.NT <- anova(model, L = c(0,0,0,0, # neutral (-) vs trauma memory
                                          0,-1, 1))
  
  valence.memory.FT <- anova(model, L = c(0,0,0,0, # fear (-) vs trauma memory
                                          -1,0, 1))
  
  valence.extinction <- anova(model, L= c(-1, 1,0,0,
                                          0,0,0)) # fear (-) vs trauma extinction
  
  
  ##Summary results organized in table
  resultMain <- data.frame(matrix(data = NA, nrow = 12, ncol = 8)) #V new
  
  # colnames(resultMain) <- c("test", 
  #                           "effectsize", "se", "ci.lb", "ci.ub", 
  #                           "Zvalue",  
  #                           "Pvalue", "Pvalue_bonfCorr")
    colnames(resultMain) <- c("test", "effectsize", "se", "ci.lb", "ci.ub", "Zvalue", "Pvalue", "Pvalue_bonfCorr")
    
  resultMain[,1] <- c(

    "neutral Learning", "neutral Memory", 
    "fear Learning", "fear Memory", "fear Extinction",
    "trauma Memory","trauma Extinction",
    
        "valence.learning: neutral vs fear (learning)", 
    "valence.memory NF: neutral vs fear (memory)", "valence.memory NT: neutral vs trauma (memory)",  "valence.memory FT: fear vs trauma (memory)",
    "valence.extinction: fear vs trauma (extinction)")
  
  resultMain[,2] <- round(c(

    neutralLearning$Lb, neutralMemory$Lb,
    fearLearning$Lb, fearMemory$Lb,  fearExtinction$Lb,
    traumaMemory$Lb, traumaExtinction$Lb,
        valence.learning$Lb, 
    valence.memory.NF$Lb, valence.memory.NT$Lb, valence.memory.FT$Lb,
    valence.extinction$Lb
    
  ), digits = 4) #effect size
  
  resultMain[,3] <- round(c(

    neutralLearning$se, neutralMemory$se,
    fearLearning$se, fearMemory$se,  fearExtinction$se,
    traumaMemory$se, traumaExtinction$se,
        valence.learning$se, 
    valence.memory.NF$se, valence.memory.NT$se, valence.memory.FT$se,
    valence.extinction$se
  ), digits = 4) #se
  
    resultMain[,4] <- round(resultMain[,2] - (resultMain[,3] * 1.96), digits = 4) #CI lower 
  resultMain[,5] <- round(resultMain[,2] + (resultMain[,3] * 1.96), digits = 4) #CI upper
  
  resultMain[,6] <- round(c(

    neutralLearning$zval, neutralMemory$zval,
    fearLearning$zval, fearMemory$zval,  fearExtinction$zval,
    traumaMemory$zval, traumaExtinction$zval,
    
        valence.learning$zval, 
    valence.memory.NF$zval, valence.memory.NT$zval, valence.memory.FT$zval,
    valence.extinction$zval
  ), digits = 4)  #zvalues
  
  resultMain[,7] <- round(c(

    neutralLearning$pval, neutralMemory$pval,
    fearLearning$pval, fearMemory$pval,  fearExtinction$pval,
    traumaMemory$pval, traumaExtinction$pval,
    
        valence.learning$pval, 
    valence.memory.NF$pval, valence.memory.NT$pval, valence.memory.FT$pval,
    valence.extinction$pval
  ), digits = 4)  #pvalues

  
  resultMain[,8] <- round(p.adjust(resultMain[,7], method = "bonferroni", n = 12),
                          digits = 4) #pvalue bonf correction
  
  return(resultMain)
  
}

TRACE_preclinical_valence_phase(mod.preclinical)->preclinical.results
```

### create plot
```{r}
preclinical.results %>% 
  filter(test %in% c("neutral Learning", "neutral Memory", 
                     "fear Learning", "fear Memory", "fear Extinction",
                     "trauma Memory","trauma Extinction"
  )) %>% 
  mutate(
    valence = ifelse(test %in% c("neutral Learning", "neutral Memory"), "Neutral", "Emotional"),
    phase = case_when(
      grepl("Learning",test) ~ "Learning", 
      grepl("Memory",test) ~ "Memory", 
      grepl("Extinction",test) ~ "Extinction"
    ),
    # signal sig. categories. Add index for p-values smaller than 0.05
    sig =ifelse(Pvalue_bonfCorr<0.05, 1, 0),
    valence= factor(valence, levels =c("Neutral", "Emotional")),
    test = factor(test, levels = c("neutral Learning", "fear Learning", "neutral Memory", "fear Memory", "trauma Memory", "fear Extinction", "trauma Extinction")#,
                  # labels = c("neutral", "fear", "neutral", "emotional", "fear")
    )
  ) ->preclinical_plot_data_coded


# https://www.datanovia.com/en/blog/ggpubr-how-to-add-p-values-generated-elsewhere-to-a-ggplot/
preclinical.results %>% 
  select(test,p=Pvalue_bonfCorr) %>% 
  filter(grepl("valence",test,fixed = T)) %>% 
  mutate(
    group1 = case_when(
      grepl("valence.learning",test) ~ "neutral Learning",
      grepl("valence.memory NF",test) ~ "neutral Memory",
      grepl("valence.memory NT",test) ~ "neutral Memory",
      grepl("valence.memory FT",test) ~ "fear Memory",
      grepl("valence.extinction",test) ~ "fear Extinction"
    ),
    group2 = case_when(
      grepl("valence.learning",test) ~ "fear Learning",
      grepl("valence.memory NF",test) ~ "fear Memory",
      grepl("valence.memory NT",test) ~ "trauma Memory",
      grepl("valence.memory FT",test) ~ "trauma Memory",
      grepl("valence.extinction",test) ~ "trauma Extinction"
    ),
    phase = case_when(
      grepl("learning",test) ~ "Learning",
      grepl("memory",test) ~ "Memory",
      grepl("extinction",test) ~ "Extinction"
    ),
    p.adj = ifelse(p == 0, yes = "p<.001", no = paste0("p=",round(p,3)))
  ) %>% group_by(phase)-> preclinical.posthoc.valence


PLOT.preclinical <-
  ggplot(preclinical_plot_data_coded,
         aes(x = test, y = effectsize, fill=valence)) +
  labs(
    title = "B) Preclinical Data: PTSD animal models",
    # subtitle = "PTSD animal models",
    y="Hedge's G (95%CI)", # could also be "Standardized mean difference"
    x="") + 
  facet_grid (.~ factor(phase, levels =c("Learning", "Memory", "Extinction")),  # width scaled (better for extinction)
              scales = "free_x", space = "free_x", switch = "x" # labels onder
              # je kan de andere factor levels nog toevoegen en dan hier drop =F, bv voor het vergelijkbaar maken met dieren?
  ) +
  # theme_linedraw() +
    theme_pubr(base_size = 12)+
  # theme(plot.title = element_text(hjust = 0.5)) +
  # theme(plot.subtitle = element_text(hjust = 0.5, face="italic")) +
  # scale_fill_manual(
  #   values= c( "Neutral" = "steelblue2", # Colours: http://sape.inf.usi.ch/quick-reference/ggplot2/colour
  #              "Emotional" = "tomato2")) +
  
     scale_fill_viridis(discrete = TRUE, #begin = 0.1, end = 0.9 , 
                        option = "cividis") +
  
  geom_bar(stat = "identity")+
  geom_hline(yintercept = 0, size = 1) +
  geom_errorbar(aes(ymin = ci.lb,
                    ymax = ci.ub),
                width = .3) +
  # theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  
  # sig marks
  geom_point(data = preclinical_plot_data_coded[preclinical_plot_data_coded$sig ==1, ],aes(x=test, y=3.6), shape = "*", size=10, show.legend = FALSE) +  # to make position dynamic use: y=ci.ub+1.5
  
  ggpubr::stat_pvalue_manual(data.frame(preclinical.posthoc.valence), inherit.aes=F,
                             y.position = 1.8, step.increase = 0.1,
                             step.group.by ="phase",
                             # label = "p = {round(p,3)}", # this works
                             label = "p.adj",
                             size=4) +
  
  scale_x_discrete(labels=c("neutral Learning" = "neutral",
                            "fear Learning" = "fear",
                            "neutral Memory" = "neutral",
                            "fear Memory" = "fear",
                            "trauma Memory" = "trauma",
                            "fear Extinction" = "fear",
                            "trauma Extinction"= "trauma"))

PLOT.preclinical
```



### save data table
save
```{r}
str(preclinical.results)
preclinical.results[,2:8]<-round(preclinical.results[,2:8],3)
# correct pvalue 0
preclinical.results %>% mutate(
  Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue),
  Pvalue_bonfCorr = ifelse(Pvalue_bonfCorr == 0, "<.001", Pvalue_bonfCorr))->preclinical.results

write.csv2(preclinical.results, "results/phase_valence_PTSD_preclinical.csv")
```


### save plots
```{r}
ggsave(paste0("results/phase_valence_PTSD_preclinical", #date(),
              ".jpg"),
       plot=PLOT.preclinical+  theme(text = element_text(size = 12)),
       device="jpg", dpi = 300, units = "cm", height = 10, width = 15, limitsize = T )

# jpeg(file="results/clinical.jpeg", height = 2000, width = 1500, res=300)
# clinical.results[[2]]
# dev.off()
```

### Diagnostics preclinical

#### Heterogeneity
```{r}
# heterogeneity from multilevel model
# heterogeneity (i2)
# http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
# dat=data6
Wp <- diag(1/preclinical$vi)
Xp <- model.matrix(mod.preclinical)
Pp <- Wp - Wp %*% Xp %*% solve(t(Xp) %*% Wp %*% Xp) %*% t(Xp) %*% Wp
100 * sum(mod.preclinical$sigma2) / (sum(mod.preclinical$sigma2) + (mod.preclinical$k-mod.preclinical$p)/sum(diag(Pp)))
```


```{r}
# between & within variance
100 * mod.preclinical$sigma2 / (sum(mod.preclinical$sigma2) + (mod.preclinical$k-mod.preclinical$p)/sum(diag(Pp)))
# sig 2.1 -> variance in xperimental group
# 5.3% within study ( experimental group) 89,4% between study ( PMID)
```

#### Publication bias: funnel
```{r}
funnel(mod.preclinical, legend = F, col=preclinical$PMID, back = 'white')
```

```{r}
tiff(file="results/funnel.colours.preclinical.tiff", height=1000, width=1000, pointsize=6, res=300)
funnel(mod.preclinical, legend = F, col=preclinical$PMID, back = 'white')
dev.off()
```

#### robustness of effect
```{r}
mod.preclinical.bias <- rma.uni(yi, vi,
                                # random = list(~1 | new.idPTSD , ~1 | PMID),
                                mods = ~valence:phase-1,
                                method = "REML",
                                slab = preclinical$reference, 
                                data = preclinical) 
# funnel(mod.preclinical.bias) # same shape as above
```

##### Egger's regression
```{r}
regtest(mod.preclinical.bias, ret.fit = TRUE) #Egger's regression random effects (mixed not available)
```

##### Begg's test
```{r eval=FALSE, include=FALSE}
regtest(preclinical$yi, preclinical$vi)
```

##### file drawer analysis (fail and safe)
```{r eval=FALSE, include=FALSE}
fsn(yi = yi, vi = vi, 
    data = preclinical, type = "Rosenthal")
```

file drawer analysis is performed within valence x phase subgroups


```{r}
fsn.table.preclinical <- data.frame(matrix(data = NA, nrow = 7, ncol = 4)) #V new

names(fsn.table.preclinical)<-c("valence", "phase", "Fail-save N", "Pvalue")

fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "F" & preclinical$phase == "E"),
    type = "Rosenthal") ->fsnFE.preclinical
fsnFE.preclinical
fsn.table.preclinical[1,] <- c("F", "E", fsnFE.preclinical$fsnum, fsnFE.preclinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "T" & preclinical$phase == "E"),
    type = "Rosenthal")->fsnTE.preclinical
fsnTE.preclinical
fsn.table.preclinical[2,] <- c("T", "E", fsnTE.preclinical$fsnum, fsnTE.preclinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "F" & preclinical$phase == "L"),
    type = "Rosenthal") ->fsnFL.preclinical
fsnFL.preclinical
fsn.table.preclinical[3,] <- c("F", "L", fsnFL.preclinical$fsnum, fsnFL.preclinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "N" & preclinical$phase == "L"),
    type = "Rosenthal")->fsnNL.preclinical
fsnNL.preclinical
fsn.table.preclinical[4,] <- c("N", "L", fsnNL.preclinical$fsnum, fsnNL.preclinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "F" & preclinical$phase == "M"),
    type = "Rosenthal")->fsnFM.preclinical
fsnFM.preclinical
fsn.table.preclinical[5,] <- c("F", "M", fsnFM.preclinical$fsnum, fsnFM.preclinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "N" & preclinical$phase == "M"),
    type = "Rosenthal")->fsnNM.preclinical
fsnNM.preclinical
fsn.table.preclinical[6,] <- c("N", "M", fsnNM.preclinical$fsnum, fsnNM.preclinical$pval)
```


```{r}
fsn(yi = yi, vi = vi, 
    data = preclinical, 
    subset = (preclinical$valence == "T" & preclinical$phase == "M"),
    type = "Rosenthal")->fsnTM.preclinical
fsnTM.preclinical
fsn.table.preclinical[7,] <- c("T", "M", fsnTM.preclinical$fsnum, fsnTM.preclinical$pval)
```

###### view and save complete table
```{r}
fsn.table.preclinical$Pvalue <- round(as.numeric(fsn.table.preclinical$Pvalue),3)
fsn.table.preclinical$Pvalue<- ifelse(fsn.table.preclinical$Pvalue == 0, "<.001",fsn.table.preclinical$Pvalue)

fsn.table.preclinical

write.csv2(fsn.table.preclinical, "results/phase_valence_PTSD_preclinical.FSN.csv")
```



##### trim and fill
only available for model without moderators, since moderation is present (with opposit effects).. not valid test for robustness of the effects?
```{r eval=FALSE, include=FALSE}
mod.preclinical.bias2 <- rma.uni(yi, vi,
                                 # random = list(~1 | new.idPTSD , ~1 | PMID),
                                 #mods = ~valence:phase-1,
                                 method = "REML",
                                 slab = preclinical$reference, 
                                 data = preclinical) 
# funnel(mod.preclinical.bias) # same shape
# summary(mod.preclinical.bias)
trimfill(mod.preclinical.bias2) 
```


### Sensitivity analysis

#### study quality
```{r}
mod.preclinical.QA <- rma.mv(yi, vi,
                             random = list(~1 | new.idPTSD , ~1 | PMID),
                             mods = ~RoB_score,#*valence:phase-1,  # valeria doet ook alleen 'blinding and randomized variable as moderator in model"
                             method = "REML",
                             slab = preclinical$reference, 
                             data = preclinical) 
summary(mod.preclinical.QA)
```


#### Influential cases
phase x valence meta-regression without cases that were identified as influential & outlier -> for sensitivity analysis
```{r eval=FALSE, include=FALSE}
preclinical.inf<-influentials_valence_phase(preclinical)
saveRDS(preclinical.inf, "processed_data/influentials.preclinical.rds")
```

```{r}
 readRDS("processed_data/influentials.preclinical.rds")->preclinical.inf
```

potential outliers and influential cases
```{r}
preclinical.inf[which(preclinical.inf$outInf == 1),] %>% nrow()
```

studies with potential outliers and influential cases
```{r}
preclinical.inf[which(preclinical.inf$outInf == 1),] %>% distinct(PMID) %>% nrow()
```

remove potential outliers and influential cases (Viechtbauer & Cheung) 
```{r}
preclinical.inf %>%
  filter(outInf != 1) %>%  # potential outliers AND influential
  # filter(potOut!=1) %>%
  droplevels() -> preclinical.noinfnoout
```

Model without potential outliers and influential cases
```{r}
mod.preclinical.noinf <- rma.mv(yi, vi,
                                random = list(~1 | new.idPTSD , ~1 | PMID),  
                                mods = ~valence:phase-1, 
                                method = "REML",
                                slab = preclinical.noinfnoout$reference,  # from old codes milou (change for author/year)
                                data = preclinical.noinfnoout) # Similar effects with dat2 (trauma learning excluded)
summary(mod.preclinical.noinf)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.preclinical.noinf$b),
        round(
                 data.frame(
                 mod.preclinical.noinf$b, mod.preclinical.noinf$se, 
                 mod.preclinical.noinf$ci.lb, mod.preclinical.noinf$ci.ub, 
                 mod.preclinical.noinf$zval, mod.preclinical.noinf$pval,row.names = NULL), 
                 3)
  ) ->sens.infout.preclinical.results

colnames(sens.infout.preclinical.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
sens.infout.preclinical.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->sens.infout.preclinical.results2

write.csv2(sens.infout.preclinical.results2,"results/sens.preclinical.infout.csv")
```


#### comparision types

##### E non-trauma exposed vs PTSD

[A= non-exposed vs trauma-exposed PTSD (human); 
E=non-exposed vs trauma-exposed PTSD (animal)
```{r}
data %>% 
  filter(subject.cat =="Animal") %>% 
  filter(comparison =="E") %>%
  droplevels() ->preclinical.HC.PTSD

preclinical.HC.PTSD %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~valence:phase-1,
       method = "REML",
       slab = preclinical.HC.PTSD$reference,
       data = preclinical.HC.PTSD) -> mod.E
mod.E%>% summary()
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.E$b),
        round(
                 data.frame(
                 mod.E$b, mod.E$se, 
                 mod.E$ci.lb, mod.E$ci.ub, 
                 mod.E$zval, mod.E$pval,row.names = NULL), 
                 3)
  ) ->mod.E.results

colnames(mod.E.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
mod.E.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->mod.E.results2

write.csv2(mod.E.results2,"results/sens.mod.E.csv")
```


##### D non-trauma exposed vs trauma-exposed HC
B=non-exposed vs trauma exposed no PTSD (human); 
D=non-exposed vs trauma-exposed (no PTSD checked) (animal)
```{r}
# Preclinical data 
data %>% 
  filter(subject.cat =="Animal") %>% 
  filter(comparison =="D") %>%
  droplevels() ->preclinical.HC.TC

preclinical.HC.TC %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~valence:phase-1,
       method = "REML",
       slab = preclinical.HC.TC$reference,
       data = preclinical.HC.TC) -> mod.D

summary(mod.D)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.D$b),
        round(
                 data.frame(
                 mod.D$b, mod.D$se, 
                 mod.D$ci.lb, mod.D$ci.ub, 
                 mod.D$zval, mod.D$pval,row.names = NULL), 
                 3)
  ) ->mod.D.results

colnames(mod.D.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
mod.D.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->mod.D.results2

write.csv2(mod.D.results2,"results/sens.mod.D.csv")
```


##### F trauma exposed vs PTSD
C=trauma-exposed (noPTSD) vs trauma-exposed PTSD (human);
F=trauma-exposed (no ptsd) vs trauma-exposed PTSD (animal)]
```{r}
# Preclinical data 
data %>% 
  filter(subject.cat =="Animal") %>% 
  filter(comparison =="F") %>%
  droplevels() ->preclinical.TC.PTSD

preclinical.TC.PTSD %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
rma.mv(yi, vi,
       random = list(~1 | new.idPTSD , ~1 | PMID),
       mods = ~valence:phase-1,
       method = "REML",
       slab = preclinical.TC.PTSD$reference,
       data = preclinical.TC.PTSD) -> mod.F

summary(mod.F)
```

```{r}
# create same structure as main analysis: effectsize	se	ci.lb	ci.ub	Zvalue	Pvalue	Pvalue_bonfCorr
  cbind(rownames(mod.F$b),
        round(
                 data.frame(
                 mod.F$b, mod.F$se, 
                 mod.F$ci.lb, mod.F$ci.ub, 
                 mod.F$zval, mod.F$pval,row.names = NULL), 
                 3)
  ) ->mod.F.results

colnames(mod.F.results)<-c("test","effectsize",	"se",	"ci.lb",	"ci.ub",	"Zvalue",	"Pvalue")

# correct pvalue 0
mod.F.results %>% mutate(Pvalue= ifelse(Pvalue == 0, "<.001", Pvalue))->mod.F.results2

write.csv2(mod.F.results2,"results/sens.mod.F.csv")
```


# Merge clinical and preclinical plots
```{r}
# Show clincal & preclinical data in one figure.
plots<-ggarrange(
  PLOT.clinical + rremove("x.axis") + rremove("x.ticks") + rremove("xlab"),
  # + rremove("y.axis") + rremove("y.ticks")
  # ,
  
  PLOT.preclinical + rremove("x.axis") + rremove("x.ticks") + rremove("xlab"),
    # +rremove("y.axis") + rremove("y.ticks")
  # ,
  ncol =1, nrow=2,
  align = "v",
  legend="bottom",
  common.legend = T)

plots
```

## safe results plots
```{r}
ggsave("results/PTSD.clinical.preclinical.jpg", 
       plot=plots,
       device="jpg", dpi = 300, height = 8, width = 6, limitsize = T )
#ggsave(paste0("LearningMemoryPTSD_TRACE_yshared", date(),".jpg"), device="jpg", dpi = 500, height = 4, width = 6, limitsize = T )
# ppt standard 4:3
```

