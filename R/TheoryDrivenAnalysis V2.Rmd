---
title: "Theory-driven meta-analysis TRACE"
author: "Milou Sep"
date: "4/21/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---

## Analysis script for TRACE analyses (based on analyses script Valeria (meta behavior))
# Code largely based on // adapted from Bonapersona, V. (2019, May 20). The behavioral phenotype of early life adversity: a 3-level meta-analysis of rodent studies. Retrieved from osf.io/ra947


# Environment Preparation
```{r setup, include=FALSE}
rm(list = ls()) #clean environment
# libraries
library(dplyr) #general
library(ggplot2) #for graphs
library(metafor) #for meta-analysis
library(ggpubr) # To show multiple plots in 1 figure
library(flextable) # to create tables
library(officer)# to export tables to word
```

# Import dataset 
(processed with merge_datasets.rmd, recode_merged_data.rmd, add_effect_size_QA.rmd)
```{r}
data<-readRDS("processed_data/TRACEprepared.RData")
```

In check_comparison.rmd script frequency of observations in groups checked


## Split clinical and preclinical data
- Clinical and preclinical data are analyzed as two separate datasets 
- comparison "B" is excluded from clinical data as it does not contain PTSD-patients 

[A= non-exposed vs trauma-exposed PTSD (human); B=non-exposed vs trauma exposed no PTSD (human); C=trauma-exposed (noPTSD) vs trauma-exposed PTSD (human); D=non-exposed vs trauma-exposed (no PTSD checked) (animal); E=non-exposed vs trauma-exposed PTSD (animal); F=trauma-exposed (no ptsd) vs trauma-exposed PTSD (animal)]

```{r}
# Clinical data 
data %>% 
  filter(subject.cat =="Human") %>% 
  filter(comparison !="B") %>%
  droplevels() ->clinical

# Preclinical data 
data %>% 
  filter(subject.cat =="Animal") %>% 
  droplevels() ->preclinical
```


# Remove subgroups with < 4 papers from analyses (by removal of data)

## Clinical
```{r}
clinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% data.frame()
```

```{r}
clinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% 
  filter(papers <4) %>% 
  mutate(
    phase.valence.code = paste(phase, valence,sep=".")
  ) ->excluded.levels.human

excluded.levels.human
```

```{r}
clinical %>% 
  mutate(phase.valence.code = paste(phase, valence,sep=".")) ->clinical1
clinical1 %>% 
  filter(!(phase.valence.code %in% excluded.levels.human$phase.valence.code)) %>% droplevels() -> clinical.filtered
```

```{r}
# for checking (should be total numbers of papers above, so here 4)
clinical1 %>% filter((phase.valence.code %in% excluded.levels.human$phase.valence.code)) %>% distinct(PMID)
```



## Preclinical
```{r}
preclinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each))
```

```{r}
preclinical %>% group_by(phase, valence) %>%
  summarize(papers=length(unique(PMID)), comparisons=length(each)) %>% 
  filter(papers <4) %>% 
  mutate(
    phase.valence.code = paste(phase, valence,sep=".")
  ) ->excluded.levels.animal

excluded.levels.animal
```


> no exclusions needed in preclinial data (levels >=4 papers)



# multilevel models


## *Research Question 1: Learning and Memory of stressful and non-stressful information in PTSD patients*

### Model - unfilterd data
```{r eval=FALSE, include=FALSE}
mod.H.total <- rma.mv(yi, vi,
                      random = list(~1 | new.idPTSD , ~1 | PMID),  # valeria had each.. ik heb in oic meta PMID.. results ong same maar beetje anders -> volgens mij is PMID de bedoeling
                      # random = ~ 1 | new.idPTSD / each,  # identical results as row above  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/fitting-a-three-level-model.html
                      # mods   = ~phase.valence - 1,
                      # mods = ~Valence_Grouped:phase-1, # all impaired  (NB E, F and T were grouped as emotional)
                      mods = ~valence:phase-1, # fear ext and fear memory impoved (trauma m NS), rest impaired
                      method = "REML",
                      slab = clinical$reference,  # from old codes milou (change for author/year)
                      data = clinical) # Similar effects with dat2 (trauma learning excluded)
summary(mod.H.total)
```

### Model - filtered data
```{r}
mod.H <- rma.mv(yi, vi,
                random = list(~1 | new.idPTSD , ~1 | PMID),  # valeria had each.. ik heb in oic meta PMID.. results ong same maar beetje anders -> volgens mij is PMID de bedoeling
                # random = ~ 1 | new.idPTSD / each,  # identical results as row above  # https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/fitting-a-three-level-model.html
                # mods   = ~phase.valence - 1,
                # mods = ~Valence_Grouped:phase-1, # all impaired  (NB E, F and T were grouped as emotional)
                mods = ~valence:phase-1, # fear ext and fear memory impoved (trauma m NS), rest impaired
                method = "REML",
                slab = clinical.filtered$reference,  # from old codes milou (change for author/year)
                data = clinical.filtered) # Similar effects with dat2 (trauma learning excluded)
summary(mod.H)
```

### add contrasts
```{r}
TRACE_clinical_valence_phase <- function(model){
  
  ##RQ 1: "Main effects PTSD on Learning and memory?
  # Learning <- anova(model, L = c(0, .5, .5, 0, 0))
  # Memory <- anova(model, L = c(0,0,0, .5, .5))
  # Extinction<-anova(model, L=c(1,0,0,0,0))
  
  
  # some info: Test linear combinations (http://www.metafor-project.org/doku.php/tips:testing_factors_lincoms)
  # http://www.metafor-project.org/doku.php/tips:multiple_factors_interactions
  
  # RQ2 "Main effects of PTSD on neutral / emotional   # 20.4.21 now the other way around (with label emotional ipv stresvull)
  # Neutral <- anova(model, L = c(0,0,.5,0,.5))
  # Emotional <- anova(model, L = c(1/3, 1/3, 0, 1/3,0))
  
  ## posthoc RQ2. is learning or memory most effected by valence? (Posthoc)
  # phase.neutral <- anova(model, L = c(0,0,-1,0,1)) 
  # phase.emotional <- anova(model, L = c(0, -1,0, 1,0)) # learning -
  
  # Posthoc RQ2 influence of valence on learning or memory
  valence.learning <-anova(model, L = c(0, 1, -1, 0,0)) # neutral = -
  valence.memory <- anova(model, L = c(0,0,0, 1, -1))
  
  
  #RQ3: neutral and stressful learning and memory in  ## PRECIES hetzelfde als de values in ht model! -> so below values from e.g. model$se used
  extinction <- anova(model, L = c(1,0, 0, 0,0))
  fearLearning <- anova(model, L = c(0,1, 0, 0,0))
  neutralLearning <- anova(model, L = c(0,0, 1, 0,0))
  emotionalMemory <- anova(model, L = c(0,0, 0, 1,0))
  neutralMemory <- anova(model, L = c(0,0, 0, 0, 1))
  
  
  ##Summary results organized in table
  resultMain <- data.frame(matrix(data = NA, nrow = 7, ncol = 8)) #V new
  
  colnames(resultMain) <- c("test", "ci.lb", "ci.ub", 
                            "effectsize", "se", "Zvalue",  
                            "Pvalue", "Pvalue_bonfCorr")
  
  resultMain[,1] <- c(#"Learning (neutral + emotional)", "Memory (neutral + emotional)", 
    #"Neutral (learning + memory)", "Emotional (learning + memory + extintion)",
    # "phase.neutral: learning vs memory (neutral)", "phase.emotional: learning vs memory (emotional)",
    "valence.learning: neutral vs emotional (learning)", "valence.memory: neutral vs emotional (memory)",
    "neutral Learning", "neutral Memory", "fear Learning", "emotional Memory", "fear Extinction")
  
  resultMain[,4] <- round(c(#Learning$Lb, Memory$Lb, 
    #Neutral$Lb, Emotional$Lb,
    # phase.neutral$Lb, phase.emotional$Lb,
    valence.learning$Lb, valence.memory$Lb,
    # model$beta
    neutralLearning$Lb, neutralMemory$Lb,
    fearLearning$Lb, emotionalMemory$Lb,
    extinction$Lb
  ), digits = 4) #effect size
  
  resultMain[,5] <- round(c(#Learning$se, Memory$se, 
    
    #Neutral$se, Emotional$se,
    
    # phase.neutral$se, phase.emotional$se,
    valence.learning$se, valence.memory$se,
    # model$beta
    neutralLearning$se, neutralMemory$se,
    fearLearning$se, emotionalMemory$se,
    extinction$se
  ), digits = 4) #se
  
  resultMain[,6] <- round(c(#Learning$zval, Memory$zval, 
    
    #Neutral$zval, Emotional$zval,
    # phase.neutral$zval, phase.emotional$zval,
    valence.learning$zval, valence.memory$zval,
    # model$beta
    neutralLearning$zval, neutralMemory$zval,
    fearLearning$zval, emotionalMemory$zval,
    extinction$zval
  ), digits = 4)  #zvalues
  
  resultMain[,7] <- round(c(#Learning$pval, Memory$pval, 
    #Neutral$pval, Emotional$pval,
    # phase.neutral$pval, phase.emotional$pval,
    valence.learning$pval, valence.memory$pval,
    neutralLearning$pval, neutralMemory$pval,
    fearLearning$pval, emotionalMemory$pval,
    extinction$pval
  ), digits = 4)  #pvalues
  
  resultMain[,2] <- round(resultMain[,4] - (resultMain[,5] * 1.96), digits = 4) #CI lower 
  resultMain[,3] <- round(resultMain[,4] + (resultMain[,5] * 1.96), digits = 4) #CI upper
  
  # 16.4.21 was 2 changed to 12, as the number of comparisons (within one hypothesis).. NB same resutls for correction by 2 or 12 (for human & animal)
  # # Beter checken! (not needed for now? only report model effect ("different from 0"), not yet the difference between each other.))
  # resultMain[,8] <- round(c(p.adjust(resultMain[ 1,7], method = "bonferroni", n = 12), # learning (I think 2, as each estimate is used once for a phase contrast (L, M) and once for a valence contrast (S,N))
  #                           p.adjust(resultMain[ 2,7], method = "bonferroni", n = 12), # memory
  #                           p.adjust(resultMain[ 3,7], method = "bonferroni", n = 12), # neutral
  #                           p.adjust(resultMain[ 4,7], method = "bonferroni", n = 12), # stressful
  #                           p.adjust(resultMain[ 5,7], method = "bonferroni", n = 12), # l vs m (neutral) (also 2 for all posthocs?)
  #                           p.adjust(resultMain[ 6,7], method = "bonferroni", n = 12), # l vs m (stress)
  #                           p.adjust(resultMain[ 7,7], method = "bonferroni", n = 12), # neutral vs stres (learning)
  #                           p.adjust(resultMain[ 8,7], method = "bonferroni", n = 12), # neutral vs stres (memory)
  #                           
  #                           p.adjust(resultMain[ 9,7], method = "bonferroni", n = 12), 
  #                           p.adjust(resultMain[ 10,7], method = "bonferroni", n = 12), 
  #                           p.adjust(resultMain[ 11,7], method = "bonferroni", n = 12), 
  #                           p.adjust(resultMain[ 12,7], method = "bonferroni", n = 12), 
  #                           p.adjust(resultMain[ 13,7], method = "bonferroni", n = 13)), 
  #                           # resultMain[9,7],
  #                           # resultMain[10,7],
  #                           # resultMain[11,7],
  #                           # resultMain[12,7])
  #                          digits = 4) #pvalue bonf correction
  
  resultMain[,8] <- round(p.adjust(resultMain[,7], method = "bonferroni", n = 7),
                          digits = 4) #pvalue bonf correction
  
  return(resultMain)
  
}

TRACE_clinical_valence_phase(mod.H)->clinical.results
```

###create plot
```{r}
clinical.results %>% 
  filter(test %in% c( "neutral Learning", "neutral Memory", "fear Learning", "emotional Memory", "fear Extinction")) %>% 
  mutate(
    valence = ifelse(test %in% c("neutral Learning", "neutral Memory"), "Neutral", "Emotional"),
    phase = case_when(
      test %in% c( "neutral Learning", "fear Learning") ~ "Learning", 
      test %in% c( "neutral Memory", "emotional Memory") ~ "Memory", 
      test == "fear Extinction" ~ "Extinction"
    ),
    # phase = factor(phase, levels = c("Learning", "Memory", "Extinction"))  # dan error with plot
    
    # signal sig. categories. Add index for p-values smaller than 0.05
    sig =ifelse(Pvalue_bonfCorr<0.05, 1, 0),
    
    valence= factor(valence, levels =c("Neutral", "Emotional")),
    # plot_data_coded$test = factor(plot_data_coded$test)
    test = factor(test, levels = c("neutral Learning", "fear Learning", "neutral Memory", "emotional Memory", "fear Extinction")#,
                  # labels = c("neutral", "fear", "neutral", "emotional", "fear")
                  
    )
  ) ->clinical_plot_data_coded


# plot_data_coded$sig<- ifelse(plot_data_coded$Pvalue_bonfCorr  <0.05, 1, 0)


# https://www.datanovia.com/en/blog/ggpubr-how-to-add-p-values-generated-elsewhere-to-a-ggplot/

clinical.results %>% 
  select(test,p=Pvalue_bonfCorr) %>% 
  filter(grepl("valence",test,fixed = T)) %>% 
  mutate(
    group1 = case_when(
      # grepl("phase.neutral",test) ~ "neutral Learning",
      #   grepl("phase.emotional",test) ~ "fear Learning"#,
      
      grepl("valence.learning",test) ~ "neutral Learning",
      grepl("valence.memory",test) ~ "neutral Memory"
    ),
    
    group2 = case_when(
      # grepl("phase.neutral",test) ~ "neutral Memory",
      # grepl("phase.emotional",test) ~ "emotional Memory"#,
      
      grepl("valence.learning",test) ~ "fear Learning",
      grepl("valence.memory",test) ~ "emotional Memory"
    ),
    
    phase = 
      case_when(
        grepl("learning",test) ~ "Learning",
        grepl("memory",test) ~ "Memory"),
    # c( "Learning", "Memory"),
    p.adj = ifelse(p == 0, yes = "p<.001", no = paste0("p=",round(p,3)))
    # valence = c("Neutral", "Emotional", NA, NA)
  ) %>% group_by(phase)-> clinical.posthoc.valence


# plot_data_coded$valence= factor(plot_data_coded$valence, levels =c("Neutral", "Emotional"))
# # plot_data_coded$test = factor(plot_data_coded$test)
# plot_data_coded$test = factor(plot_data_coded$test, levels = c("neutral Learning", "fear Learning", "neutral Memory", "emotional Memory", "fear Extinction")#,
#                               # labels = c("neutral", "fear", "neutral", "emotional", "fear")
# )

PLOT.clinical <-
  ggplot(clinical_plot_data_coded,
         aes(x = test, y = effectsize, fill=valence)) +
  labs(
    title = "Clinical Data",
    subtitle = "PTSD patients",
    y="Hedge's G (CI)", # could also be "Standardized mean difference"
    x="") + 
  facet_grid (.~ factor(phase, levels =c("Learning", "Memory", "Extinction")),  # width scaled (better for extinction)
              scales = "free_x", space = "free_x", switch = "x" # labels onder
              # je kan de andere factor levels nog toevoegen en dan hier drop =F, bv voor het vergelijkbaar maken met dieren?
  ) +
  theme_linedraw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5, face="italic")) +
  scale_fill_manual(
    values= c( "Neutral" = "steelblue2", # Colours: http://sape.inf.usi.ch/quick-reference/ggplot2/colour
               "Emotional" = "tomato2")) +
  geom_bar(stat = "identity")+
  geom_hline(yintercept = 0, size = 1) +
  geom_errorbar(aes(ymin = ci.lb,
                    ymax = ci.ub),
                width = .3) +
  # theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  
  # sig marks
  geom_point(data = clinical_plot_data_coded[clinical_plot_data_coded$sig ==1, ],aes(x=test, y=1), shape = "*", size=10, show.legend = FALSE) +  # to make position dynamic use: y=ci.ub+1.5
  
  # y_sig_position <- 1 #  ifelse(title=='Clinical Data', 1  , 3.3 )
  #  title='Preclinical Data'
  
  ggpubr::stat_pvalue_manual( data.frame(clinical.posthoc.valence), inherit.aes=F,
                              y.position = 0.3, 
                              # label = "p = {round(p,3)}", 
                              label =  "p.adj",
                              
                              size=4) +
  
  scale_x_discrete(labels=c("neutral Learning" = "neutral", 
                            "fear Learning" = "fear",
                            "neutral Memory" = "neutral",
                            "emotional Memory" = "emotional",
                            "fear Extinction" = "fear"))

PLOT.clinical
```

### run function & save plots
```{r}
write.csv2(clinical.results, paste0("results/phase_valence_PTSD_clinical", #date(),
                                    ".csv"))
ggsave(paste0("results/phase_valence_PTSD_clinical", #date(),
              ".jpg"),
       plot=PLOT.clinical+  theme(text = element_text(size = 12)),
       device="jpg", dpi = 300, units = "cm", height = 10, width = 15, limitsize = T )

# jpeg(file="results/clinical.jpeg", height = 2000, width = 1500, res=300)
# clinical.results[[2]]
# dev.off()
```

```{r eval=FALSE, fig.height=40, fig.width=8, include=FALSE}
forest(mod.H, cex = .2)

# clinical %>% filter(yi > 4) %>% View()
# clinical %>% filter(measure.d == "EXT_%CS+/maxCS+Acq_EMG") %>% View()
```


### diagnostics clinical

#### Heterogeneity
out oic meta code
"The I² statistic was used to assess heterogeneity of effect sizes. According to Higgins et al. (2003) values of 25, 50 and 75% are indicative of low, moderate and high heterogeneity, respectively. Rosenthal’s fail-safe N was used to assess the robustness of effect sizes. Fail-safe N determines the number of studies with effect size 0 that would be necessary to cancel out significant effect sizes. Effect sizes were considered robust when N values>5k + 10, where k refers to the number of studies used in the meta-analysis (Rosenthal, 1995). The possibility of publication bias was also assessed by Egger Funnel plot asymmetry (Egger et al., 1997) and all reported significance tests were two tailed with α = .05." [Sep MSC, Steenmeijer A, Kennis M. The relation between anxious personality traits and fear generalization in healthy subjects: A systematic review and meta-analysis. Neurosci Biobehav Rev 2019; 107: 320–328.]


```{r}
# heterogeneity from multilevel model
# heterogeneity (i2)
# http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
# dat=data6
Wc <- diag(1/clinical.filtered$vi)
Xc <- model.matrix(mod.H)
Pc <- Wc - Wc %*% Xc %*% solve(t(Xc) %*% Wc %*% Xc) %*% t(Xc) %*% Wc
100 * sum(mod.H$sigma2) / (sum(mod.H$sigma2) + (mod.H$k-mod.H$p)/sum(diag(Pc)))
```


```{r}
# between & within variance
100 * mod.H$sigma2 / (sum(mod.H$sigma2) + (mod.H$k-mod.H$p)/sum(diag(Pc)))
# sig 2.1 -> variance in xperimental group
# 8.55% within study ( experimental group) 75,4% between study ( PMID)
```



#### Publication bias: funnel

```{r}
tiff(file="results/funnel.colours.clinical.tiff", height=1500, width=1500, pointsize=8, res=300)
funnel(mod.H, legend = F, col=clinical.filtered$PMID, 
       back = 'white'#,xlab='mean DR'
       )
dev.off()
```



#### robustness of effect
```{r}
# #random effects model for evaluation of publication bias
# modRanEff <- rma.uni(yi, vi,
#                      #random = list(~1 | each, ~1 | exp),
#                      mods = ~domain:hit2Grouped - 1,
#                      method = "REML",
#                      digits = 3,
#                      data = dat)

mod.H.bias <- rma.uni(yi, vi,
                # random = list(~1 | new.idPTSD , ~1 | PMID),
                mods = ~valence:phase-1,
                method = "REML",
                slab = clinical.filtered$reference, 
                data = clinical.filtered) 
# summary(mod.A.bias)
```

##### Egger's regression
```{r}
regtest(mod.H.bias, ret.fit = TRUE) #Egger's regression random effects (mixed not available)
```





##### Begg's test
```{r}
regtest(clinical.filtered$yi, clinical.filtered$vi)
```

##### file drawer analysis (fail and safe)
```{r}
fsn(yi = yi, vi = vi, 
           data = clinical.filtered, type = "Rosenthal")
```


##### trim and fill
```{r}
mod.H.bias2 <- rma.uni(yi, vi,
                # random = list(~1 | new.idPTSD , ~1 | PMID),
                #mods = ~valence:phase-1,
                method = "REML",
                slab = clinical.filtered$reference, 
                data = clinical.filtered) 
# summary(mod.A.bias)
trimfill(mod.H.bias2) # only available for model with moderators
```






## *Research Question 2: Learning and Memory of emotional and non-emotional information in animal models of PTSD*

### Model
```{r}
mod.A <- rma.mv(yi, vi,
                random = list(~1 | new.idPTSD , ~1 | PMID),
                mods = ~valence:phase-1,
                method = "REML",
                slab = preclinical$reference, 
                data = preclinical) 
summary(mod.A)
```

```{r eval=FALSE, fig.height=80, fig.width=8, include=FALSE}
forest(mod.A, cex = 0.4)
```

### add contrasts
```{r}
TRACE_preclinical_valence_phase <- function(model){
  
  valence.learning <-anova(model, L = c(0,0,1,-1,
                                        0,0,0)) # neutral (-) vs fear learning
  
  # valence.memoryNS <- anova(model, L = c(0,0,0,0,
  #                                      0.5,-1, 0.5)) # neural =- (fear & trauma together compared to neutral)
  
  valence.memory.NF <- anova(model, L = c(0,0,0,0, # neutral (-) vs fear memory
                                          1,-1, 0))
  
  valence.memory.NT <- anova(model, L = c(0,0,0,0, # neutral (-) vs trauma memory
                                          0,-1, 1))
  
  valence.memory.FT <- anova(model, L = c(0,0,0,0, # fear (-) vs trauma memory
                                          -1,0, 1))
  
  valence.extinction <- anova(model, L= c(-1, 1,0,0,
                                          0,0,0)) # fear (-) vs trauma extinction
  
  #RQ3: neutral and stressful learning and memory in 
  fearExtinction <- anova(model, L = c(1,0, 0, 0,0,0,0))
  traumaExtinction <-anova(model, L = c(0,1, 0, 0,0,0,0))
  
  fearLearning <- anova(model, L = c(0,0,1, 0,0,0,0))
  neutralLearning <- anova(model, L = c(0,0,0, 1, 0,0,0))
  # emotionalMemory <- anova(model, L = c(0,0, 0, 1,0,0,0))
  fearMemory <- anova(model, L = c(0,0, 0,0,1,0,0))
  neutralMemory <- anova(model, L = c(0,0, 0, 0, 0,1,0))
  traumaMemory <- anova(model, L = c(0,0, 0, 0, 0,0,1))
  
  
  ##Summary results organized in table
  resultMain <- data.frame(matrix(data = NA, nrow = 12, ncol = 8)) #V new
  
  colnames(resultMain) <- c("test", "ci.lb", "ci.ub", 
                            "effectsize", "se", "Zvalue",  
                            "Pvalue", "Pvalue_bonfCorr")
  
  resultMain[,1] <- c(
    "valence.learning: neutral vs fear (learning)", 
    "valence.memory NF: neutral vs fear (memory)", "valence.memory NT: neutral vs trauma (memory)",  "valence.memory FT: fear vs trauma (memory)",
    "valence.extinction: fear vs trauma (extinction)",
    "neutral Learning", "neutral Memory", 
    "fear Learning", "fear Memory", "fear Extinction",
    "trauma Memory","trauma Extinction")
  
  resultMain[,4] <- round(c(
    valence.learning$Lb, 
    valence.memory.NF$Lb, valence.memory.NT$Lb, valence.memory.FT$Lb,
    valence.extinction$Lb,
    neutralLearning$Lb, neutralMemory$Lb,
    fearLearning$Lb, fearMemory$Lb,  fearExtinction$Lb,
    traumaMemory$Lb, traumaExtinction$Lb
    
  ), digits = 4) #effect size
  
  resultMain[,5] <- round(c(
    valence.learning$se, 
    valence.memory.NF$se, valence.memory.NT$se, valence.memory.FT$se,
    valence.extinction$se,
    neutralLearning$se, neutralMemory$se,
    fearLearning$se, fearMemory$se,  fearExtinction$se,
    traumaMemory$se, traumaExtinction$se
  ), digits = 4) #se
  
  resultMain[,6] <- round(c(
    valence.learning$zval, 
    valence.memory.NF$zval, valence.memory.NT$zval, valence.memory.FT$zval,
    valence.extinction$zval,
    neutralLearning$zval, neutralMemory$zval,
    fearLearning$zval, fearMemory$zval,  fearExtinction$zval,
    traumaMemory$zval, traumaExtinction$zval
  ), digits = 4)  #zvalues
  
  resultMain[,7] <- round(c(
    valence.learning$pval, 
    valence.memory.NF$pval, valence.memory.NT$pval, valence.memory.FT$pval,
    valence.extinction$pval,
    neutralLearning$pval, neutralMemory$pval,
    fearLearning$pval, fearMemory$pval,  fearExtinction$pval,
    traumaMemory$pval, traumaExtinction$pval
  ), digits = 4)  #pvalues
  
  resultMain[,2] <- round(resultMain[,4] - (resultMain[,5] * 1.96), digits = 4) #CI lower 
  resultMain[,3] <- round(resultMain[,4] + (resultMain[,5] * 1.96), digits = 4) #CI upper
  
  resultMain[,8] <- round(p.adjust(resultMain[,7], method = "bonferroni", n = 12),
                          digits = 4) #pvalue bonf correction
  
  return(resultMain)
  
}

TRACE_preclinical_valence_phase(mod.A)->preclinical.results
```

### create plot
```{r}
preclinical.results %>% 
  filter(test %in% c("neutral Learning", "neutral Memory", 
                       "fear Learning", "fear Memory", "fear Extinction",
                       "trauma Memory","trauma Extinction"
  )) %>% 
  mutate(
    valence = ifelse(test %in% c("neutral Learning", "neutral Memory"), "Neutral", "Emotional"),
    phase = case_when(
      grepl("Learning",test) ~ "Learning", 
      grepl("Memory",test) ~ "Memory", 
      grepl("Extinction",test) ~ "Extinction"
    ),
    # signal sig. categories. Add index for p-values smaller than 0.05
    sig =ifelse(Pvalue_bonfCorr<0.05, 1, 0),
    valence= factor(valence, levels =c("Neutral", "Emotional")),
    test = factor(test, levels = c("neutral Learning", "fear Learning", "neutral Memory", "fear Memory", "trauma Memory", "fear Extinction", "trauma Extinction")#,
                  # labels = c("neutral", "fear", "neutral", "emotional", "fear")
    )
  ) ->preclinical_plot_data_coded


# https://www.datanovia.com/en/blog/ggpubr-how-to-add-p-values-generated-elsewhere-to-a-ggplot/
preclinical.results %>% 
  select(test,p=Pvalue_bonfCorr) %>% 
  filter(grepl("valence",test,fixed = T)) %>% 
  mutate(
    group1 = case_when(
      grepl("valence.learning",test) ~ "neutral Learning",
      grepl("valence.memory NF",test) ~ "neutral Memory",
      grepl("valence.memory NT",test) ~ "neutral Memory",
      grepl("valence.memory FT",test) ~ "fear Memory",
      grepl("valence.extinction",test) ~ "fear Extinction"
    ),
    group2 = case_when(
      grepl("valence.learning",test) ~ "fear Learning",
      grepl("valence.memory NF",test) ~ "fear Memory",
      grepl("valence.memory NT",test) ~ "trauma Memory",
      grepl("valence.memory FT",test) ~ "trauma Memory",
      grepl("valence.extinction",test) ~ "trauma Extinction"
    ),
    phase = case_when(
      grepl("learning",test) ~ "Learning",
      grepl("memory",test) ~ "Memory",
      grepl("extinction",test) ~ "Extinction"
    ),
    p.adj = ifelse(p == 0, yes = "p<.001", no = paste0("p=",round(p,3)))
  ) %>% group_by(phase)-> preclinical.posthoc.valence


PLOT.preclinical <-
  ggplot(preclinical_plot_data_coded,
         aes(x = test, y = effectsize, fill=valence)) +
  labs(
    title = "Preclinical Data",
    subtitle = "PTSD animal models",
    y="Hedge's G (CI)", # could also be "Standardized mean difference"
    x="") + 
  facet_grid (.~ factor(phase, levels =c("Learning", "Memory", "Extinction")),  # width scaled (better for extinction)
              scales = "free_x", space = "free_x", switch = "x" # labels onder
              # je kan de andere factor levels nog toevoegen en dan hier drop =F, bv voor het vergelijkbaar maken met dieren?
  ) +
  theme_linedraw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(plot.subtitle = element_text(hjust = 0.5, face="italic")) +
  scale_fill_manual(
    values= c( "Neutral" = "steelblue2", # Colours: http://sape.inf.usi.ch/quick-reference/ggplot2/colour
               "Emotional" = "tomato2")) +
  geom_bar(stat = "identity")+
  geom_hline(yintercept = 0, size = 1) +
  geom_errorbar(aes(ymin = ci.lb,
                    ymax = ci.ub),
                width = .3) +
  # theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  
  # sig marks
  geom_point(data = preclinical_plot_data_coded[preclinical_plot_data_coded$sig ==1, ],aes(x=test, y=3.6), shape = "*", size=10, show.legend = FALSE) +  # to make position dynamic use: y=ci.ub+1.5
  
  ggpubr::stat_pvalue_manual(data.frame(preclinical.posthoc.valence), inherit.aes=F,
                             y.position = 1.8, step.increase = 0.1,
                             step.group.by ="phase",
                             # label = "p = {round(p,3)}", # this works
                             label = "p.adj",
                             size=4) +
  
  scale_x_discrete(labels=c("neutral Learning" = "neutral",
                            "fear Learning" = "fear",
                            "neutral Memory" = "neutral",
                            "fear Memory" = "fear",
                            "trauma Memory" = "trauma",
                            "fear Extinction" = "fear",
                            "trauma Extinction"= "trauma"))

PLOT.preclinical
```



### run function & save plots
```{r}
# TRACE_clinical_valence_phase(mod.H) ->clinical.results
# clinical.results [[2]] +  theme(text = element_text(size = 12)) 

# save
write.csv2(preclinical.results, paste0("results/phase_valence_PTSD_preclinical", #date(),
                                       ".csv"))
ggsave(paste0("results/phase_valence_PTSD_preclinical", #date(),
              ".jpg"),
       plot=PLOT.preclinical+  theme(text = element_text(size = 12)),
       device="jpg", dpi = 300, units = "cm", height = 10, width = 15, limitsize = T )

# jpeg(file="results/clinical.jpeg", height = 2000, width = 1500, res=300)
# clinical.results[[2]]
# dev.off()
```

### Diagnostics preclinical

#### Heterogeneity
```{r}
# heterogeneity from multilevel model
# heterogeneity (i2)
# http://www.metafor-project.org/doku.php/tips:i2_multilevel_multivariate
# dat=data6
Wp <- diag(1/preclinical$vi)
Xp <- model.matrix(mod.A)
Pp <- Wp - Wp %*% Xp %*% solve(t(Xp) %*% Wp %*% Xp) %*% t(Xp) %*% Wp
100 * sum(mod.A$sigma2) / (sum(mod.A$sigma2) + (mod.A$k-mod.A$p)/sum(diag(Pp)))
```


```{r}
# between & within variance
100 * mod.A$sigma2 / (sum(mod.A$sigma2) + (mod.A$k-mod.H$p)/sum(diag(Pp)))
# sig 2.1 -> variance in xperimental group
# 5.3% within study ( experimental group) 89,4% between study ( PMID)
```

#### Publication bias: funnel
```{r}
tiff(file="results/funnel.colours.preclinical.tiff", height=1500, width=1500, pointsize=8, res=300)
funnel(mod.A, legend = F, col=preclinical$PMID, back = 'white'#,xlab='mean DR'
       )
dev.off()
```


#### robustness of effect
```{r}
# #random effects model for evaluation of publication bias
# modRanEff <- rma.uni(yi, vi,
#                      #random = list(~1 | each, ~1 | exp),
#                      mods = ~domain:hit2Grouped - 1,
#                      method = "REML",
#                      digits = 3,
#                      data = dat)

mod.A.bias <- rma.uni(yi, vi,
                # random = list(~1 | new.idPTSD , ~1 | PMID),
                mods = ~valence:phase-1,
                method = "REML",
                slab = preclinical$reference, 
                data = preclinical) 
# summary(mod.A.bias)
```

##### Egger's regression
```{r}
regtest(mod.A.bias, ret.fit = TRUE) #Egger's regression random effects (mixed not available)
```

##### Begg's test
```{r}
regtest(preclinical$yi, preclinical$vi)
```

##### file drawer analysis (fail and safe)
```{r}
fsn(yi = yi, vi = vi, 
           data = preclinical, type = "Rosenthal")
```


##### trim and fill
```{r}
mod.A.bias2 <- rma.uni(yi, vi,
                # random = list(~1 | new.idPTSD , ~1 | PMID),
                #mods = ~valence:phase-1,
                method = "REML",
                slab = preclinical$reference, 
                data = preclinical) 
# summary(mod.A.bias)
trimfill(mod.A.bias2) # only available for model with moderators
```


## Merge clinical and preclinical plots
```{r}
# Show clincal & preclinical data in one figure.
plots<-ggarrange(
  PLOT.clinical
  #  + ylim(-7.5,3.5)  # If you want y-axis the same for clinical and preclinical
  # + rremove("x.text") 
  + rremove("x.axis") + rremove("x.ticks") + rremove("xlab")
  + rremove("y.axis") + rremove("y.ticks"),
  
  PLOT.preclinical
  # + ylim(-7.5,3.5)   # If you want y-axis the same for clinical and preclinical
  # + rremove("x.text") 
  + rremove("x.axis") + rremove("x.ticks") + rremove("xlab")
  + #rremove("ylab") + 
    rremove("y.axis") + rremove("y.ticks"),
  ncol =1, nrow=2,
  align = "v",
  legend="bottom",
  common.legend = T)

plots
```

## **safe results**
```{r}
ggsave(paste0("results/PTSD.clinical.preclinical", #date(),
              ".jpg"), 
       plot=plots,
       device="jpg", dpi = 300, height = 8, width = 6, limitsize = T )
#ggsave(paste0("LearningMemoryPTSD_TRACE_yshared", date(),".jpg"), device="jpg", dpi = 500, height = 4, width = 6, limitsize = T )
# ppt standard 4:3
```



# Sensitivity analysis

## study quality

### Clinical
```{r}
mod.H.QA <- rma.mv(yi, vi,
                random = list(~1 | new.idPTSD , ~1 | PMID),  
                # mods = ~valence:phase-1, 
                   mods = ~QA_score,#*valence:phase-1,  # valeria doet ook alleen 'blinding and randomized variable as moderator in model"
                method = "REML",
                slab = clinical.filtered$reference, 
                data = clinical.filtered) 
summary(mod.H.QA)
```

### Preclinical
```{r}
# str(preclinical)
mod.A.QA <- rma.mv(yi, vi,
                random = list(~1 | new.idPTSD , ~1 | PMID),
                mods = ~QA_score,#*valence:phase-1,  # valeria doet ook alleen 'blinding and randomized variable as moderator in model"
                method = "REML",
                slab = preclinical$reference, 
                data = preclinical) 
summary(mod.A.QA)
```



## Influential cases
phase x valence meta-regression

without cases that were identified as influential &outlier -> for sensitivity analysis
```{r}
source("R/influentials_valence_phase.R")
```


### clinical
```{r}
clinical.inf<-influentials_valence_phase(clinical.filtered)
#saveRDS(clinical.inf, "processed_data/influentials.clinical.rds")
# readRDS("processed_data/influentials.clinical.rds")->clinical.inf

# potential outlier and influential cases
clinical.inf[which(clinical.inf$outInf == 1),] %>% nrow()# 15 comparisons
clinical.inf[which(clinical.inf$outInf == 1),]%>% distinct(PMID) %>% nrow() # 7 papers

# # potential outliers
# clinical.inf[which(clinical.inf$potOut == 1),] %>% nrow()# 15 comparision 
# clinical.inf[which(clinical.inf$potOut == 1),]%>% distinct(PMID) %>% nrow()

# remove outliers
##  influential (Viechtbauer & Cheung) 
clinical.inf %>%
  filter(outInf != 1) %>%
  droplevels() -> clinical.noinfout
```


```{r}
mod.H.noinf <- rma.mv(yi, vi,
                             random = list(~1 | new.idPTSD , ~1 | PMID),  
                mods = ~valence:phase-1, 
                method = "REML",
                      slab = clinical.noinfout$reference,  # from old codes milou (change for author/year)
                      data = clinical.noinfout) # Similar effects with dat2 (trauma learning excluded)

summary(mod.H.noinf)
```


### preclinical
```{r}
preclinical.inf<-influentials_valence_phase(preclinical)
#saveRDS(preclinical.inf, "processed_data/influentials.preclinical.rds")
# readRDS("processed_data/influentials.preclinical.rds")->preclinical.inf

# potential outlier and influential cases
preclinical.inf[which(preclinical.inf$outInf == 1),] %>% nrow() # 11 comparisons
preclinical.inf[which(preclinical.inf$outInf == 1),] %>% distinct(PMID) %>% nrow() # 4 papers

# preclinical.inf %>% filter(outInf == 1 & potOut==1) %>% nrow() # 11 comparisons
# preclinical.inf %>% filter(outInf == 1 & potOut==1) %>% distinct(PMID) %>% nrow() # 4 papers

# # potential outliers
# preclinical.inf[which(preclinical.inf$potOut == 1),] %>% nrow() # 28 comparisons
# preclinical.inf[which(preclinical.inf$potOut == 1),] %>% distinct(PMID) %>% nrow() # 14 papers
# preclinical.inf %>% filter(potOut!=1) #->data.sens

# remove outliers
##  influential (Viechtbauer & Cheung) 
# preclinical.inf %>%
#  filter(outInf != 1) %>%
# droplevels() -> preclinical.noinf # n=4 papers (11 comparison) excluded animal 

preclinical.inf %>%
  filter(outInf != 1) %>%  # potential outliers AND influential
  # filter(potOut!=1) %>%
  droplevels() -> preclinical.noinfnoout
```

```{r}
mod.A.noinf <- rma.mv(yi, vi,
                random = list(~1 | new.idPTSD , ~1 | PMID),  
                mods = ~valence:phase-1, 
                method = "REML",
                      slab = preclinical.noinfnoout$reference,  # from old codes milou (change for author/year)
                      data = preclinical.noinfnoout) # Similar effects with dat2 (trauma learning excluded)
summary(mod.A.noinf)
```


## comparision types?

